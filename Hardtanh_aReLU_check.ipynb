{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn.functional as F\n",
    "\n",
    "L = 20 # multiplier coef\n",
    "eps = 0.0\n",
    "eps_V = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, end_maxpool = False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        if self.end_maxpool:\n",
    "            out = F.relu(out, inplace=False)\n",
    "        else:\n",
    "            out = F.hardtanh(out, inplace=False, min_val=-1.0, max_val=1.0)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2, end_maxpool = True)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, end_maxpool = False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                layers.append(block(self.inplanes, planes, end_maxpool = True))\n",
    "            else:\n",
    "                layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_Hardtanh_ReLUmaxpool.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na ISNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    #### Check ####\n",
    "    V = torch.matmul((tj - t_min).type(dtype), torch.maximum(W.type(dtype), torch.zeros(W.type(dtype).shape)))\n",
    "    if((V>threshold).any()):\n",
    "        print(f\"ERROR SpikingDense V {V}, thr {threshold}\") \n",
    "    ### END Check ###\n",
    "\n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.multiplier = 1\n",
    "        self.mul = 1\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.W = kernel.clone()\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.W = kernel.clone()\n",
    "                self.B = bias.clone().unsqueeze(0)\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1 ):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), self.B))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.B, torch.zeros(self.B.shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))+eps_V\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        \n",
    "        if self.bias:\n",
    "            self.kernel = nn.Parameter(torch.concat((self.W.clone()*(in_scalar/(self.multiplier)),self.B.clone()/(self.multiplier))))\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(self.W.clone()*(in_scalar/(self.multiplier)))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), self.kernel[-1].unsqueeze(0)))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.kernel[-1].unsqueeze(0), torch.zeros(self.kernel[-1].unsqueeze(0).shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))+eps_V/(self.multiplier)\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            # print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel*(in_scalar),torch.zeros(self.kernel.shape).to(self.device))\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1))\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))))+eps_V\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))+eps_V\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "            \n",
    "        else:\n",
    "            if minimal_t_max-self.t_min==0:\n",
    "                self.multiplier = (self.t_max - self.t_min)+eps\n",
    "            else:\n",
    "                self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        self.kernel_mul = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_W = torch.maximum(self.kernel*self.kernel_mul,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier)\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))/self.multiplier))+eps_V/(self.multiplier)\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))+eps_V/(self.multiplier)\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), max_values, self.multiplier\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        #### Check ####\n",
    "        V = torch.matmul((tj - t_min), torch.maximum(W, torch.zeros(W.shape)))\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SpikingConv2D V {V}, thr {threshold}\") \n",
    "        ### END Check ###\n",
    "\n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # Wyciąganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "\n",
    "            ti = self.call_spiking(tj, W * self.kernel_mul, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W * self.kernel_mul,self.B.T / self.multiplier),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul1\n",
    "        max_V = max(output_val)+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "\n",
    "        ### Check ###\n",
    "        tj1_temp = (tj2-tj1)*(tj1<tj2)\n",
    "        tj2_temp = (tj1-tj2)*(tj1>tj2)\n",
    "\n",
    "        V = tj1_temp*self.mul1 + tj2_temp*self.mul2\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR AddSNNLayer1 V {V}, thr {threshold}\")\n",
    "\n",
    "        V = tj1*self.mul1 + tj2*self.mul2 - (self.mul1+self.mul2)*self.t_min\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR AddSNNLayer2 V {V}, thr {threshold}\")\n",
    "        \n",
    "        ### END Check ###\n",
    "        ti = tj1*self.mul1 + tj2*self.mul2 - (self.mul1+self.mul2)*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.multiplier = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1\n",
    "        self.input1_val = input1_val\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1\n",
    "        max_V = max(output_val)+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ### Check ###\n",
    "        if(len(tj1.shape) == 3):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(1, 2))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(1, 2))-self.input1_val).max()}\")\n",
    "        elif(len(tj1.shape) == 4):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(2, 3))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(2, 3))-self.input1_val).max()}\")\n",
    "        tj1_temp = (tj2-tj1)*(tj1<tj2)\n",
    "        tj2_temp = (tj1-tj2)*(tj1>=tj2)\n",
    "\n",
    "        V = tj1_temp*self.mul1 - tj2_temp*self.mul2\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "            print(f\"{((tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2).max()}\")\n",
    "\n",
    "        V = (tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "        \n",
    "        ### END Check ###\n",
    "\n",
    "        ti = (tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \n",
    "        max_input = max(in_ranges_max*in_scalar)\n",
    "        max_V = max_input+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        self.mul1 = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_input = max(in_ranges_max*self.mul1)\n",
    "        max_V = max_input+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), in_ranges_max*self.mul1, self.multiplier\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "\n",
    "        V = (tj - self.t_min)*self.mul1\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR IdentitySNNLayer V {V.max()}, thr {threshold}\")\n",
    "        \n",
    "        ti = (tj - self.t_min)*self.mul1  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar = in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2  = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_resblock0 = model2.layer0[0](model_maxpool)\n",
    "model_resblock1 = model2.layer0[1](model_resblock0)\n",
    "model_resblock2 = model2.layer0[2](model_resblock1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_Htanh(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_Htanh, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        \n",
    "        kernels_neg = torch.concat((-kernels,kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_neg = -biases\n",
    "        else:\n",
    "            biases_neg = None\n",
    "\n",
    "        kernels_new = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new = torch.concat((biases_pos, biases_neg))\n",
    "        # print(biases_new.shape)\n",
    "        self.conv_first = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "        \n",
    "        kernels_new2 = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new2 = torch.concat((biases_pos, biases_neg)) - 1\n",
    "        self.conv_second = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new2, biases=biases_new2)\n",
    "        self.sub = SubSNNLayer()\n",
    "        self.filters = filters*2\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        if(in_ranges_max.shape[0] != self.filters):\n",
    "            in_ranges_max = torch.concat((in_ranges_max,torch.zeros(in_ranges_max.shape)))\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.conv_second.set_params(t_min_prev, t_min, in_ranges_max, tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, tmax2, in_scalar=in_scalar)\n",
    "        self.t_max = tmax1\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        # tmaxs = max(min(tmaxs,tmins+1.0/in_scalar_sub)+eps_V, minimal_t_max)\n",
    "        tmaxs = max(tmaxs, minimal_t_max)\n",
    "        self.sub.t_max = tmaxs\n",
    "        self.t_max = tmaxs\n",
    "        # Returning for function signature consistency\n",
    "        return tmins, self.t_max, torch.minimum(sub_val, torch.ones(sub_val.shape)/in_scalar_sub), in_scalar_sub\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        tj2 = self.conv_second(tj)\n",
    "        tj_sub = self.sub(tj1, tj2)\n",
    "\n",
    "        return tj_sub\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_all(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, bias=0):\n",
    "        super(AddSNNLayer_all, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.B = bias # bias for all inputs (for Hard tanh)\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        self.input1_val = input1_val\n",
    "        if input2_val.shape[0] != input1_val.shape[0]:\n",
    "            input2_val = torch.concat((input2_val, torch.zeros(input2_val.shape)))\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2 + self.B\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "            \n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min + eps)/(max(minimal_t_max-self.t_min,1.0/L))\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "\n",
    "        #### adding epsilon block\n",
    "        self.multiplier_temp = self.multiplier\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2 + self.B\n",
    "        max_V = max(output_val)+eps_V*self.multiplier_temp\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "            \n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min + eps)/(max(minimal_t_max-self.t_min,1.0/L))\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        #### adding epsilon block\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul2 + self.B/self.multiplier\n",
    "        max_V = max(output_val)+eps_V*self.multiplier_temp/(self.multiplier)\n",
    "        print(f\"epsilon: {eps_V/(self.multiplier)}, mul: {self.multiplier}\")\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "\n",
    "        self.channels = tj1.shape[1]//2\n",
    "\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        #### Check ####\n",
    "        if(len(tj1.shape) == 3):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(1, 2))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(1, 2))-self.input1_val).max()}\")\n",
    "        elif(len(tj1.shape) == 4):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(2, 3))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(2, 3))-self.input1_val).max()}\")\n",
    "        tj1_temp = tj1[0, :self.channels].detach().clone()\n",
    "        tj2_temp = tj1[0, self.channels:].detach().clone()\n",
    "        tj3_temp = tj2[0, :self.channels].detach().clone()\n",
    "        tj4_temp = tj2[0, self.channels:].detach().clone()\n",
    "\n",
    "        stacked = torch.stack([tj1_temp, tj2_temp, tj3_temp, tj4_temp], dim=0)\n",
    "\n",
    "        min_times_list = []\n",
    "        mask_list = []\n",
    "\n",
    "        for i in range(4):\n",
    "            min_indices = torch.argmin(stacked, dim=0)\n",
    "\n",
    "\n",
    "            min_vals = stacked.gather(0, min_indices.unsqueeze(0)).squeeze(0)\n",
    "            min_times_list.append(min_vals)\n",
    "\n",
    "            mask = torch.zeros_like(stacked, dtype=torch.bool)\n",
    "            C, X, Y = min_indices.shape\n",
    "            c_idx, x_idx, y_idx = torch.meshgrid(\n",
    "                torch.arange(C), torch.arange(X), torch.arange(Y), indexing=\"ij\"\n",
    "            )\n",
    "            mask[min_indices, c_idx, x_idx, y_idx] = True\n",
    "            if i!=0:\n",
    "                mask_list.append(torch.logical_or(mask,mask_list[-1]))\n",
    "            else:\n",
    "                mask_list.append(mask)\n",
    "            stacked = torch.where(mask, torch.full_like(stacked, float('inf')), stacked)\n",
    "        min_times_list.append(self.t_max*torch.ones(min_times_list[0].shape))\n",
    "\n",
    "        min_times = torch.stack(min_times_list, dim=0)\n",
    "        mask_list = torch.stack(mask_list, dim=0)\n",
    "        vect = -torch.tensor([self.mul1,-self.mul1, self.mul2, -self.mul2])\n",
    "        V_plus = torch.zeros(min_times[0].shape) + (0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[0]-self.t_min)))\n",
    "        V_minus = torch.zeros(min_times[0].shape) + (0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[0]-self.t_min)))\n",
    "        for i in range(4):\n",
    "            duration = min_times[i+1] - min_times[i]\n",
    "            if i!=0:\n",
    "                mask_list[i] =  torch.logical_or(mask_list[i], mask_list[i-1])\n",
    "            V_plus += ((mask_list[i].to(torch.float64).T)@vect).T * duration + ( 0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[i+1]-min_times[i])) )\n",
    "            if((V_plus>threshold).any()):\n",
    "                print(f\"ERROR AddSNNLayer_all V {V_plus.max()}, thr {threshold}\")\n",
    "            V_minus += (-((mask_list[i].to(torch.float64).T)@vect).T * duration) + ( 0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[i+1]-min_times[i])) )\n",
    "            if((V_minus>threshold).any()):\n",
    "                print(f\"ERROR AddSNNLayer_all V {V_minus.max()}, thr {threshold}\")\n",
    "        V2 = (tj1[0, :self.channels] - tj1[0, self.channels:])*self.mul1 + (tj2[0, :self.channels] - tj2[0, self.channels:])*self.mul2 + self.B/(self.multiplier)*(1)\n",
    "        if ((V2 - V_plus).abs().max() > 0.00001):\n",
    "            print(f\"WARNING AddSNNLayer_all too big difference in chceck: {(V2 - V_plus).abs().max()}\")\n",
    "        V2 = (tj1[0, self.channels:] - tj1[0, :self.channels])*self.mul1 + (tj2[0, self.channels:] - tj2[0, :self.channels])*self.mul2 + self.B/(self.multiplier)*(1)\n",
    "        if ((V2 - V_minus).abs().max() > 0.00001):\n",
    "            print(f\"WARNING AddSNNLayer_all too big difference in chceck: {(V2 - V_minus).abs().max()}\")\n",
    "        \n",
    "\n",
    "        #### END Check ####\n",
    "        ti = torch.concat(((tj1[0, :self.channels]- tj1[0, self.channels:])*self.mul1 + (tj2[0, :self.channels]  - tj2[0, self.channels:])*self.mul2, \n",
    "                           (tj1[0, self.channels:] - tj1[0, :self.channels])*self.mul1 + (tj2[0, self.channels:] - tj2[0, :self.channels])*self.mul2)) + self.B/(self.multiplier)*(1) + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_Htanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer_Htanh, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.first = AddSNNLayer_all()\n",
    "        self.second = AddSNNLayer_all(1)\n",
    "        self.sub = SubSNNLayer()\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        tmin2, tmax2, second_val, in_scalar_second = self.second.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax1, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax2, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar_first, in_scalar2=in_scalar_second) ## t_min as angument do nothing\n",
    "        self.sub.t_max = max(tmaxs, minimal_t_max)\n",
    "        return tmins, max(tmaxs, minimal_t_max), torch.minimum(sub_val,(1.0/in_scalar_sub)), in_scalar_sub\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        tj_first = self.first(tj1, tj2)\n",
    "        tj_second = self.second(tj1, tj2)\n",
    "        tj_sub = self.sub(tj_first, tj_second)\n",
    "        return tj_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_all(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_all, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        kernels_new = kernels_pos\n",
    "        biases_new = biases_pos\n",
    "        self.conv_first = SpikingConv2D(filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, out_scalar = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar = in_scalar)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return tmin1, tmax1, first_val, out_scalar\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        return tj1\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock_all(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\", end_maxpool = False):\n",
    "        super(ResidualSNNBlock_all, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        if (downsample is not None):\n",
    "            self.conv1 = SpikingConv2D_all(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        else:\n",
    "            self.conv1 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        if end_maxpool:\n",
    "            self.add_layer = AddSNNLayer_all()\n",
    "        else:\n",
    "            self.add_layer = AddSNNLayer_Htanh()\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.t_max1 = t_max1\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.t_max1_dummy = t_max1_dummy\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "            residual = torch.concat((residual,torch.ones(residual.shape)*self.t_max1_dummy), dim=1)\n",
    "            out = torch.concat((out,torch.ones(out.shape)*self.t_max1), dim=1)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        # print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual) # no need for adding negative part\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN_all(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0', end_maxpool = False):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D_all(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock_all(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device, end_maxpool = True))\n",
    "            else:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            # print(i)\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(71.1718, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "max_vect = torch.tensor([1,1,1,1,1])\n",
    "tmin, tmax, max_vect, scalar = conv_first.set_params(0,1,max_vect)\n",
    "print(tmin, tmax, scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "print(model_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9775e-06, 0.0000e+00, 9.1083e-04, 3.9515e-04, 0.0000e+00, 1.4991e-02,\n",
      "        4.9621e-09, 0.0000e+00, 2.6293e-05, 0.0000e+00, 2.2074e-07, 8.0345e-07,\n",
      "        2.4908e-08, 2.7611e-07, 0.0000e+00, 2.0023e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.0948e-04, 0.0000e+00, 4.5383e-04, 2.2796e-02,\n",
      "        0.0000e+00, 5.1981e-04, 7.9895e-04, 1.6889e-08, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.0456e-08, 0.0000e+00, 1.2533e-04, 0.0000e+00,\n",
      "        2.1487e-04, 0.0000e+00, 6.5975e-04, 0.0000e+00, 7.5714e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1994e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2233e-07, 5.3934e-05, 7.6377e-04,\n",
      "        0.0000e+00, 0.0000e+00, 8.0127e-05, 2.0703e-02],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tworzenie przykładowego array'a\n",
    "values = max_vect.detach().numpy()\n",
    "labels = [ i for i in range(len(max_vect))]\n",
    "\n",
    "# Tworzenie wykresu słupkowego\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "\n",
    "# Dodanie etykiet\n",
    "plt.ylabel('$x_{max}$')\n",
    "plt.xlabel('Channel number')\n",
    "plt.title('maksymalne wartości każdego kanału')\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 224, 224])\n",
      "tensor(7.9572e-06, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "\n",
    "# SNN_input = torch.concat((SNN_input, torch.ones(SNN_input.shape)),dim=1)\n",
    "print(SNN_input.shape)\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "# print(out1)\n",
    "out1_x = model2.conv1(random_input)\n",
    "temp = (conv_first.t_max - out1)*scalar\n",
    "# print((temp[0,:64] - temp[0,64:] - model_conv1).abs().max())\n",
    "print((temp - model_conv1).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9572e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "\n",
    "print(((tmax - out2)*scalar - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "addsnn2 = AddSNNLayer_all(1)\n",
    "addsnn1 = AddSNNLayer_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 2.4999500009761398e-08, mul: 40.00080000038146\n",
      "epsilon: 1.6666333339893902e-08, mul: 60.00120000038148\n",
      "epsilon: 2.499950118354948e-08, mul: 40.00079812224549\n",
      "torch.Size([10, 224, 224])\n",
      "tensor(6.9737e-06)\n",
      "tensor(2.0500, dtype=torch.float64)\n",
      "tensor(2.0500, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "SNN_input1 = 1 - random_input +1\n",
    "SNN_input2 = 1 - random_input +1\n",
    "\n",
    "val_in1, val_in2 = torch.concat((torch.ones(5), torch.zeros(5))),torch.concat((torch.ones(5), torch.zeros(5)))\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2)\n",
    "\n",
    "tmin2, tmax2, val2, scalar2 = addsnn2.set_params(0+1,1+1,val_in1,val_in2,tmax1)\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2,tmax2)\n",
    "\n",
    "outadd1 = addsnn1(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd1.shape)\n",
    "print((((tmax1 - outadd1)[:5] - (tmax1 - outadd1)[5:])*scalar1 - F.relu(random_input*2)).abs().max())# \n",
    "print(tmax1)\n",
    "print(tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(1.0337e-05)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "outadd2 = addsnn2(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd2.shape)\n",
    "print((((tmax1 - outadd2)[:5] - (tmax1 - outadd2)[5:])*scalar2 - F.relu(random_input*2-1)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = SubSNNLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "tmins, tmaxs, sub_val, scalar_sub = sub.set_params(0, tmax1, val1,val2, in_scalar1=scalar1, in_scalar2=scalar2)\n",
    "sub.t_max = tmaxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4782e-05)\n"
     ]
    }
   ],
   "source": [
    "outsub = sub(outadd1,outadd2)\n",
    "print((((sub.t_max-outsub)[:5] - (sub.t_max-outsub)[5:])*scalar_sub - F.hardtanh(random_input*2)).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resblock test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [],
   "source": [
    "resblocksnn = ResidualSNNBlock_all(model2.layer0[0],64,64, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.3778395228969018e-08, mul: 72.57739260501863\n",
      "epsilon: 1.0801726546521594e-08, mul: 92.5777926050186\n",
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "tensor(1.3000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(72.5760, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmin2, tmax2, max_vect2, scalar1 = resblocksnn.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin2, tmax2, scalar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "print(torch.concat((out2, torch.ones(out2.shape) * tmin),dim=1).shape)\n",
    "out3res = resblocksnn(torch.concat((out2, torch.ones(out2.shape) * tmax),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0138, grad_fn=<MaxBackward1>)\n",
      "tensor(2.5243e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out3res)[:64].max())\n",
    "print((((tmax2 - out3res)[:64] - (tmax2 - out3res)[64:])*scalar1  - model_resblock0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tmax, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.700606065640596e-08, mul: 21.273852478504182\n",
      "epsilon: 2.4228179553846665e-08, mul: 41.27425247850418\n",
      "epsilon: 4.700606065640596e-08, mul: 21.273852478504182\n",
      "tensor(1.6000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.6500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn2 = ResidualSNNBlock_all(model2.layer0[1],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn2.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar1)\n",
    "print(tmin2, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [],
   "source": [
    "out4res = resblocksnn2(out3res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0470, grad_fn=<MaxBackward1>)\n",
      "tensor(2.6494e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out4res)[:64].max())\n",
    "print((((tmax2 - out4res)[:64] - (tmax2 - out4res)[64:])*scalar2  - model_resblock1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.617130831132199e-08, mul: 21.65847225418091\n",
      "epsilon: 2.4004490421596553e-08, mul: 41.658872254180906\n",
      "epsilon: 4.6171310479308e-08, mul: 21.65847123720166\n",
      "tensor(1.9000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn3 = ResidualSNNBlock_all(model2.layer0[2],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn3.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar2)\n",
    "print(tmin2, tmax2)\n",
    "out5res = resblocksnn3(out4res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0462, grad_fn=<MaxBackward1>)\n",
      "tensor(2.6941e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out5res)[:64].max())\n",
    "print((((tmax2 - out5res)[:64] - (tmax2 - out5res)[64:])*scalar2  - model_resblock2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = None\n",
    "\n",
    "# resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy, device='cpu')\n",
    "# tmin, tmax, max_vect = resblockSNN.set_params(0,1, max_vect)\n",
    "# print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.3778395228969018e-08, mul: 72.57739260501863\n",
      "epsilon: 1.0801726546521594e-08, mul: 92.5777926050186\n",
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "epsilon: 4.700606065640596e-08, mul: 21.273852478504182\n",
      "epsilon: 2.4228179553846665e-08, mul: 41.27425247850418\n",
      "epsilon: 4.700606065640596e-08, mul: 21.273852478504182\n",
      "epsilon: 4.617130831132199e-08, mul: 21.65847225418091\n",
      "epsilon: 2.4004490421596553e-08, mul: 41.658872254180906\n",
      "epsilon: 4.6171310479308e-08, mul: 21.65847123720166\n",
      "tensor(1.9000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN_all(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmax_prev = tmax\n",
    "tmin, tmax, max_vect,scalar = layer0SNN.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 56, 56])\n",
      "tensor(2.6941e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(torch.concat((out2, torch.ones(out2.shape) * tmax_prev),dim=1))\n",
    "print(out_3.shape)\n",
    "print((((tmax - out_3)[:64] - (tmax - out_3)[64:])*scalar - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.529837679235192e-08, mul: 65.36641197776795\n",
      "epsilon: 1.1714154210894392e-08, mul: 85.36681197776794\n",
      "epsilon: 1.529837679235192e-08, mul: 65.36641197776795\n",
      "epsilon: 4.7785949725771944e-08, mul: 20.926653247213363\n",
      "epsilon: 2.4433715827726794e-08, mul: 40.92705370933487\n",
      "epsilon: 4.7785951970007423e-08, mul: 20.926652264406997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.7786156613486355e-08, mul: 20.926562646341324\n",
      "epsilon: 2.443377161645323e-08, mul: 40.92696026210785\n",
      "epsilon: 4.778615661348636e-08, mul: 20.92656264634132\n",
      "epsilon: 4.7784109592825725e-08, mul: 20.927459118127825\n",
      "epsilon: 2.4433237573766947e-08, mul: 40.927854811744744\n",
      "epsilon: 4.77841153968139e-08, mul: 20.927456576221914\n",
      "tensor(3.0500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.1000, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN_all(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer1SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING SubSNNLayer input times not in declared range mismach: 1.9961325961048715e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 2.1922296582488343e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 2.234355633845553e-06\n",
      "torch.Size([256, 28, 28])\n",
      "tensor(8.8871e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "print((tmax - out_4).shape)\n",
    "print((((tmax - out_4)[ :128] - (tmax - out_4)[ 128:])*scalar - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.2074518252519018e-08, mul: 82.81903916053771\n",
      "epsilon: 9.725787342981364e-09, mul: 102.8194391605377\n",
      "epsilon: 1.2074518252519018e-08, mul: 82.81903916053771\n",
      "epsilon: 4.116655734838295e-08, mul: 24.291562482070912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 2.2577460806045975e-08, mul: 44.29196040204007\n",
      "epsilon: 4.116655928163921e-08, mul: 24.2915613412951\n",
      "epsilon: 4.0050951184364086e-08, mul: 24.96819602103234\n",
      "epsilon: 2.223774001110296e-08, mul: 44.968598405265794\n",
      "epsilon: 4.0050951184364086e-08, mul: 24.96819602103234\n",
      "epsilon: 4.441447517718661e-08, mul: 22.515182179021842\n",
      "epsilon: 2.3520786795538122e-08, mul: 42.51558456325531\n",
      "epsilon: 4.441447517718661e-08, mul: 22.515182179021842\n",
      "epsilon: 4.1029327342479394e-08, mul: 24.372810006189347\n",
      "epsilon: 2.2536121538015647e-08, mul: 44.37320762195588\n",
      "epsilon: 4.10293292689992e-08, mul: 24.37280886177139\n",
      "epsilon: 4.025005271418127e-08, mul: 24.844687958574294\n",
      "epsilon: 2.229898744071465e-08, mul: 44.84508557434083\n",
      "epsilon: 4.0250054604106866e-08, mul: 24.84468679200167\n",
      "tensor(4.8000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.8500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN_all(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer2SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING SubSNNLayer input times not in declared range mismach: 1.176285877590999e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 1.0162802936974913e-06\n",
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print((((tmax - out_5)[:256] - (tmax - out_5)[256:])*scalar - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\2564355837.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.4693849757470235e-08, mul: 68.05568428325654\n",
      "epsilon: 1.1356398687718455e-08, mul: 88.05608428325651\n",
      "epsilon: 1.4693849757470237e-08, mul: 68.05568428325653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 2.499950298993438e-08, mul: 40.00079523191452\n",
      "epsilon: 1.6666336688757165e-08, mul: 60.00118794399392\n",
      "epsilon: 2.499950602644748e-08, mul: 40.00079037330097\n",
      "epsilon: 2.4999500009761385e-08, mul: 40.000800000381474\n",
      "tensor(5.6000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.6500, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN_all(model2.layer3, 256, 512, 3,device = 'cpu',end_maxpool=True)\n",
    "tmin, tmax, max_vect,scalar = layer3SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING SubSNNLayer input times not in declared range mismach: 3.4288730148546165e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 5.757501185144065e-06\n",
      "tensor(0.0007, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print((((tmax - out_6)[:512])*scalar - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6[:512])\n",
    "\n",
    "print(((tmax - out7)*scalar - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.7000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(289.2210, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin_, tmax_, max_vect_, scalar_ = spiking_dense.set_params(tmin, tmax, max_vect[:512], in_scalar=scalar)\n",
    "print(tmin_, tmax_, scalar_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0011, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "\n",
    "print(((tmax_ - out8)*scalar_ - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(1.1000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.1500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.2000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.2500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.3000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.3500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.4000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.4500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.5000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.5500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.6000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.6500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.7000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.7500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.8000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.8500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.9000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.9500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.9500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.0000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.0500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.1000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.1500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.2000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.2500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.3000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.3500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.4000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.4500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.5000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.5500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.6000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.6500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.7000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.7500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.8000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.8500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.9000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.9500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.0000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.0500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.1000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.1000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.1500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.2000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.2500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.3000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.3500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.4000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.4500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.5000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.5500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.6000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.6500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.7000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.7500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.8000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.8500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.9000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.9500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.0000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.0500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.1000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.1500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.2000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.2500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.3000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.3500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.4000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.4500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.5000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.5500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.6000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.6500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.7000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.7500, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.8000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.8500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.8500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.9000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.9500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.0500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.1000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(5.1500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.2000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.2500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.3000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.3500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.4000, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(5.4500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.5000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.5500, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.6000, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.6000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.6500, dtype=torch.float64, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'czas')"
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(tt)\n",
    "plt.xlabel(\"Nr. warstwy\")\n",
    "plt.ylabel(\"czas\")\n",
    "# plt.ylim([0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [(tt[i])/(tt[i-1]) for i in range(2,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d8863ceee0>]"
      ]
     },
     "execution_count": 1376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_positive_tanH(nn.Module):\n",
    "    \"\"\"\n",
    "    from positive to all and Hard tanh\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        b2 = torch.concatenate((biases, -biases)) - 1\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.second = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((input_units,), W.detach().clone(), b1)\n",
    "        self.second.build((input_units,), W.detach().clone(), b2)\n",
    "        self.sub_layer = SubSNNLayer()\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.second.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax2, in_scalar=in_scalar)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub_layer.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2) ## t_min as angument do nothing\n",
    "        self.sub_layer.t_max = min(tmaxs,tmins+(1/in_scalar_sub))+eps_V\n",
    "        return tmins, min(tmaxs,tmins+(1/in_scalar_sub))+eps_V, torch.maximum(sub_val, 1/in_scalar_sub), in_scalar_sub\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        out2 = self.second(tj)\n",
    "        sub_ = self.sub_layer(out1,out2)\n",
    "        return sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "input_ttfs = out7.view(out7.size(0), -1)\n",
    "input_x = (tmax - input_ttfs)*scalar\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "scalar__ = scalar\n",
    "max_vect__ = max_vect\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model2.fc.weight.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "\n",
    "layer = SpikingDense_positive_tanH(10,512, '',weights, biases,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7000, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.7034, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(294.8974, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer.set_params(t_min__, t_max__, max_vect__[:512], in_scalar=scalar__)\n",
    "print(t_min, t_max, scalar___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - F.hardtanh(out_x)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_all_all(nn.Module):\n",
    "    \"\"\"\n",
    "    from all to all (pure linear layer)\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W1 = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        W2 = torch.concatenate((-weights.T, weights.T),dim=1)\n",
    "        W = torch.concatenate((W1,W2),dim=0)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((2*input_units,), W, b1)\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin1, tmax1, first_val, in_scalar\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sh = list(input_ttfs.shape)\n",
    "sh[1] = sh[1]\n",
    "binary_mask = torch.randint(0,2,sh)\n",
    "binary_mask = torch.concat((binary_mask, 1-binary_mask),dim=1)\n",
    "sh[1] = sh[1]*2\n",
    "\n",
    "input_ttfs = (torch.rand(sh)*(tmax - tmin) + tmin) * binary_mask\n",
    "input_x = ((tmax - input_ttfs[0,:512]) - (tmax - input_ttfs[0,512:]))*scalar__\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "max_vect__ = torch.rand(1024)\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)\n",
    "print(input_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = SpikingDense_all_all(10,512, '',model2.fc.weight, model2.fc.bias,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_3284\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer2.set_params(t_min__, t_max__, max_vect__, scalar__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0017, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer2.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - out_x).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7000, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
