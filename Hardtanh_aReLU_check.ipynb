{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn.functional as F\n",
    "\n",
    "L = 20 # multiplier coef\n",
    "eps = 0.0\n",
    "eps_V = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, end_maxpool = False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        if self.end_maxpool:\n",
    "            out = F.relu(out, inplace=False)\n",
    "        else:\n",
    "            out = F.hardtanh(out, inplace=False, min_val=-1.0, max_val=1.0)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2, end_maxpool = True)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, end_maxpool = False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                layers.append(block(self.inplanes, planes, end_maxpool = True))\n",
    "            else:\n",
    "                layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikos\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_Hardtanh_ReLUmaxpool.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na ISNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    #### Check ####\n",
    "    V = torch.matmul((tj - t_min).type(dtype), torch.maximum(W.type(dtype), torch.zeros(W.type(dtype).shape)))\n",
    "    if((V>threshold).any()):\n",
    "        print(f\"ERROR SpikingDense V {V}, thr {threshold}\") \n",
    "    ### END Check ###\n",
    "\n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.multiplier = 1\n",
    "        self.mul = 1\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.W = kernel.clone()\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.W = kernel.clone()\n",
    "                self.B = bias.clone().unsqueeze(0)\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1 ):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), self.B))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.B, torch.zeros(self.B.shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))+eps_V\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        \n",
    "        if self.bias:\n",
    "            self.kernel = nn.Parameter(torch.concat((self.W.clone()*(in_scalar/(self.multiplier)),self.B.clone()/(self.multiplier))))\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(self.W.clone()*(in_scalar/(self.multiplier)))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), self.kernel[-1].unsqueeze(0)))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.kernel[-1].unsqueeze(0), torch.zeros(self.kernel[-1].unsqueeze(0).shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))+eps_V/(self.multiplier)\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            # print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel*(in_scalar),torch.zeros(self.kernel.shape).to(self.device))\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1))\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))))+eps_V\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))+eps_V\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "            \n",
    "        else:\n",
    "            if minimal_t_max-self.t_min==0:\n",
    "                self.multiplier = (self.t_max - self.t_min)+eps\n",
    "            else:\n",
    "                self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        self.kernel_mul = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_W = torch.maximum(self.kernel*self.kernel_mul,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier)\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))/self.multiplier))+eps_V/(self.multiplier)\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))+eps_V/(self.multiplier)\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), max_values, self.multiplier\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        #### Check ####\n",
    "        V = torch.matmul((tj - t_min), torch.maximum(W, torch.zeros(W.shape)))\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SpikingConv2D V {V}, thr {threshold}\") \n",
    "        ### END Check ###\n",
    "\n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # Wyciąganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "\n",
    "            ti = self.call_spiking(tj, W * self.kernel_mul, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W * self.kernel_mul,self.B.T / self.multiplier),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul1\n",
    "        max_V = max(output_val)+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "\n",
    "        ### Check ###\n",
    "        tj1_temp = (tj2-tj1)*(tj1<tj2)\n",
    "        tj2_temp = (tj1-tj2)*(tj1>tj2)\n",
    "\n",
    "        V = tj1_temp*self.mul1 + tj2_temp*self.mul2\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR AddSNNLayer1 V {V}, thr {threshold}\")\n",
    "\n",
    "        V = tj1*self.mul1 + tj2*self.mul2 - (self.mul1+self.mul2)*self.t_min\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR AddSNNLayer2 V {V}, thr {threshold}\")\n",
    "        \n",
    "        ### END Check ###\n",
    "        ti = tj1*self.mul1 + tj2*self.mul2 - (self.mul1+self.mul2)*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.multiplier = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1\n",
    "        self.input1_val = input1_val\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1\n",
    "        max_V = max(output_val)+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ### Check ###\n",
    "        if(len(tj1.shape) == 3):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(1, 2))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(1, 2))-self.input1_val).max()}\")\n",
    "        elif(len(tj1.shape) == 4):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(2, 3))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(2, 3))-self.input1_val).max()}\")\n",
    "        tj1_temp = (tj2-tj1)*(tj1<tj2)\n",
    "        tj2_temp = (tj1-tj2)*(tj1>=tj2)\n",
    "\n",
    "        V = tj1_temp*self.mul1 - tj2_temp*self.mul2\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "            print(f\"{((tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2).max()}\")\n",
    "\n",
    "        V = (tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "        \n",
    "        ### END Check ###\n",
    "\n",
    "        ti = (tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \n",
    "        max_input = max(in_ranges_max*in_scalar)\n",
    "        max_V = max_input+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        self.mul1 = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_input = max(in_ranges_max*self.mul1)\n",
    "        max_V = max_input+eps_V/(self.multiplier)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), in_ranges_max*self.mul1, self.multiplier\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "\n",
    "        V = (tj - self.t_min)*self.mul1\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR IdentitySNNLayer V {V.max()}, thr {threshold}\")\n",
    "        \n",
    "        ti = (tj - self.t_min)*self.mul1  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar = in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2  = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_resblock0 = model2.layer0[0](model_maxpool)\n",
    "model_resblock1 = model2.layer0[1](model_resblock0)\n",
    "model_resblock2 = model2.layer0[2](model_resblock1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_Htanh(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_Htanh, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        \n",
    "        kernels_neg = torch.concat((-kernels,kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_neg = -biases\n",
    "        else:\n",
    "            biases_neg = None\n",
    "\n",
    "        kernels_new = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new = torch.concat((biases_pos, biases_neg))\n",
    "        # print(biases_new.shape)\n",
    "        self.conv_first = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "        \n",
    "        kernels_new2 = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new2 = torch.concat((biases_pos, biases_neg)) - 1\n",
    "        self.conv_second = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new2, biases=biases_new2)\n",
    "        self.sub = SubSNNLayer()\n",
    "        self.filters = filters*2\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        if(in_ranges_max.shape[0] != self.filters):\n",
    "            in_ranges_max = torch.concat((in_ranges_max,torch.zeros(in_ranges_max.shape)))\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.conv_second.set_params(t_min_prev, t_min, in_ranges_max, tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, tmax2, in_scalar=in_scalar)\n",
    "        self.t_max = tmax1\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        # tmaxs = max(min(tmaxs,tmins+1.0/in_scalar_sub)+eps_V, minimal_t_max)\n",
    "        tmaxs = max(tmaxs, minimal_t_max)\n",
    "        tmaxs = max(min(tmaxs,tmins+1.0/in_scalar_sub)+eps_V, minimal_t_max)\n",
    "        self.sub.t_max = tmaxs\n",
    "        self.t_max = tmaxs\n",
    "        # Returning for function signature consistency\n",
    "        return tmins, self.t_max, torch.minimum(sub_val, torch.ones(sub_val.shape)/in_scalar_sub), in_scalar_sub\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        tj2 = self.conv_second(tj)\n",
    "        tj_sub = self.sub(tj1, tj2)\n",
    "\n",
    "        return tj_sub\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_all(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, bias=0):\n",
    "        super(AddSNNLayer_all, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.B = bias # bias for all inputs (for Hard tanh)\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        self.input1_val = input1_val\n",
    "        if input2_val.shape[0] != input1_val.shape[0]:\n",
    "            input2_val = torch.concat((input2_val, torch.zeros(input2_val.shape)))\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2 + self.B\n",
    "        max_V = max(output_val)+eps_V\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "            \n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min + eps)/(max(minimal_t_max-self.t_min,1.0/L))\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "\n",
    "        #### adding epsilon block\n",
    "        self.multiplier_temp = self.multiplier\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2 + self.B\n",
    "        max_V = max(output_val)+eps_V*self.multiplier_temp\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "            \n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min + eps)/(max(minimal_t_max-self.t_min,1.0/L))\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        #### adding epsilon block\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul2 + self.B/self.multiplier\n",
    "        max_V = max(output_val)+eps_V*self.multiplier_temp/(self.multiplier)\n",
    "        print(f\"epsilon: {eps_V/(self.multiplier)}, mul: {self.multiplier}\")\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "\n",
    "        self.channels = tj1.shape[1]//2\n",
    "\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        #### Check ####\n",
    "        if(len(tj1.shape) == 3):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(1, 2))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(1, 2))-self.input1_val).max()}\")\n",
    "        elif(len(tj1.shape) == 4):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(2, 3))>(self.input1_val+eps_V)).any()):\n",
    "                print(f\"WARNING SubSNNLayer input times not in declared range mismach: {(torch.amax(self.t_min - tj1, dim=(2, 3))-self.input1_val).max()}\")\n",
    "        tj1_temp = tj1[0, :self.channels].detach().clone()\n",
    "        tj2_temp = tj1[0, self.channels:].detach().clone()\n",
    "        tj3_temp = tj2[0, :self.channels].detach().clone()\n",
    "        tj4_temp = tj2[0, self.channels:].detach().clone()\n",
    "\n",
    "        stacked = torch.stack([tj1_temp, tj2_temp, tj3_temp, tj4_temp], dim=0)\n",
    "\n",
    "        min_times_list = []\n",
    "        mask_list = []\n",
    "\n",
    "        for i in range(4):\n",
    "            min_indices = torch.argmin(stacked, dim=0)\n",
    "\n",
    "\n",
    "            min_vals = stacked.gather(0, min_indices.unsqueeze(0)).squeeze(0)\n",
    "            min_times_list.append(min_vals)\n",
    "\n",
    "            mask = torch.zeros_like(stacked, dtype=torch.bool)\n",
    "            C, X, Y = min_indices.shape\n",
    "            c_idx, x_idx, y_idx = torch.meshgrid(\n",
    "                torch.arange(C), torch.arange(X), torch.arange(Y), indexing=\"ij\"\n",
    "            )\n",
    "            mask[min_indices, c_idx, x_idx, y_idx] = True\n",
    "            if i!=0:\n",
    "                mask_list.append(torch.logical_or(mask,mask_list[-1]))\n",
    "            else:\n",
    "                mask_list.append(mask)\n",
    "            stacked = torch.where(mask, torch.full_like(stacked, float('inf')), stacked)\n",
    "        min_times_list.append(self.t_max*torch.ones(min_times_list[0].shape))\n",
    "\n",
    "        min_times = torch.stack(min_times_list, dim=0)\n",
    "        mask_list = torch.stack(mask_list, dim=0)\n",
    "        vect = -torch.tensor([self.mul1,-self.mul1, self.mul2, -self.mul2])\n",
    "        V_plus = torch.zeros(min_times[0].shape) + (0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[0]-self.t_min)))\n",
    "        V_minus = torch.zeros(min_times[0].shape) + (0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[0]-self.t_min)))\n",
    "        for i in range(4):\n",
    "            duration = min_times[i+1] - min_times[i]\n",
    "            if i!=0:\n",
    "                mask_list[i] =  torch.logical_or(mask_list[i], mask_list[i-1])\n",
    "            V_plus += ((mask_list[i].to(torch.float64).T)@vect).T * duration + ( 0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[i+1]-min_times[i])) )\n",
    "            if((V_plus>threshold).any()):\n",
    "                print(f\"ERROR AddSNNLayer_all V {V_plus.max()}, thr {threshold}\")\n",
    "            V_minus += (-((mask_list[i].to(torch.float64).T)@vect).T * duration) + ( 0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[i+1]-min_times[i])) )\n",
    "            if((V_minus>threshold).any()):\n",
    "                print(f\"ERROR AddSNNLayer_all V {V_minus.max()}, thr {threshold}\")\n",
    "        V2 = (tj1[0, :self.channels] - tj1[0, self.channels:])*self.mul1 + (tj2[0, :self.channels] - tj2[0, self.channels:])*self.mul2 + self.B/(self.multiplier)*(1)\n",
    "        if ((V2 - V_plus).abs().max() > 0.00001):\n",
    "            print(f\"WARNING AddSNNLayer_all too big difference in chceck: {(V2 - V_plus).abs().max()}\")\n",
    "        V2 = (tj1[0, self.channels:] - tj1[0, :self.channels])*self.mul1 + (tj2[0, self.channels:] - tj2[0, :self.channels])*self.mul2 + self.B/(self.multiplier)*(1)\n",
    "        if ((V2 - V_minus).abs().max() > 0.00001):\n",
    "            print(f\"WARNING AddSNNLayer_all too big difference in chceck: {(V2 - V_minus).abs().max()}\")\n",
    "        \n",
    "\n",
    "        #### END Check ####\n",
    "        ti = torch.concat(((tj1[0, :self.channels]- tj1[0, self.channels:])*self.mul1 + (tj2[0, :self.channels]  - tj2[0, self.channels:])*self.mul2, \n",
    "                           (tj1[0, self.channels:] - tj1[0, :self.channels])*self.mul1 + (tj2[0, self.channels:] - tj2[0, :self.channels])*self.mul2)) + self.B/(self.multiplier)*(1) + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_Htanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer_Htanh, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.first = AddSNNLayer_all()\n",
    "        self.second = AddSNNLayer_all(1)\n",
    "        self.sub = SubSNNLayer()\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        tmin2, tmax2, second_val, in_scalar_second = self.second.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax1, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax2, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar_first, in_scalar2=in_scalar_second) ## t_min as angument do nothing\n",
    "        self.sub.t_max = max(tmaxs, minimal_t_max)\n",
    "        return tmins, max(tmaxs, minimal_t_max), torch.minimum(sub_val,(1.0/in_scalar_sub)), in_scalar_sub\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        tj_first = self.first(tj1, tj2)\n",
    "        tj_second = self.second(tj1, tj2)\n",
    "        tj_sub = self.sub(tj_first, tj_second)\n",
    "        return tj_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_all(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_all, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        kernels_new = kernels_pos\n",
    "        biases_new = biases_pos\n",
    "        self.conv_first = SpikingConv2D(filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, out_scalar = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar = in_scalar)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return tmin1, tmax1, first_val, out_scalar\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        return tj1\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock_all(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\", end_maxpool = False):\n",
    "        super(ResidualSNNBlock_all, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        if (downsample is not None):\n",
    "            self.conv1 = SpikingConv2D_all(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        else:\n",
    "            self.conv1 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        if end_maxpool:\n",
    "            self.add_layer = AddSNNLayer_all()\n",
    "        else:\n",
    "            self.add_layer = AddSNNLayer_Htanh()\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.t_max1 = t_max1\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.t_max1_dummy = t_max1_dummy\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "            residual = torch.concat((residual,torch.ones(residual.shape)*self.t_max1_dummy), dim=1)\n",
    "            out = torch.concat((out,torch.ones(out.shape)*self.t_max1), dim=1)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        # print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual) # no need for adding negative part\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN_all(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0', end_maxpool = False):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D_all(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock_all(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device, end_maxpool = True))\n",
    "            else:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            # print(i)\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(71.1718, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "max_vect = torch.tensor([1,1,1,1,1])\n",
    "tmin, tmax, max_vect, scalar = conv_first.set_params(0,1,max_vect)\n",
    "print(tmin, tmax, scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "print(model_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9775e-06, 0.0000e+00, 9.1083e-04, 3.9515e-04, 0.0000e+00, 1.4991e-02,\n",
      "        4.9621e-09, 0.0000e+00, 2.6293e-05, 0.0000e+00, 2.2074e-07, 8.0345e-07,\n",
      "        2.4908e-08, 2.7611e-07, 0.0000e+00, 2.0023e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.0948e-04, 0.0000e+00, 4.5383e-04, 2.2796e-02,\n",
      "        0.0000e+00, 5.1981e-04, 7.9895e-04, 1.6889e-08, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.0456e-08, 0.0000e+00, 1.2533e-04, 0.0000e+00,\n",
      "        2.1487e-04, 0.0000e+00, 6.5975e-04, 0.0000e+00, 7.5714e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1994e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2233e-07, 5.3934e-05, 7.6377e-04,\n",
      "        0.0000e+00, 0.0000e+00, 8.0127e-05, 2.0703e-02],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tworzenie przykładowego array'a\n",
    "values = max_vect.detach().numpy()\n",
    "labels = [ i for i in range(len(max_vect))]\n",
    "\n",
    "# Tworzenie wykresu słupkowego\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "\n",
    "# Dodanie etykiet\n",
    "plt.ylabel('$x_{max}$')\n",
    "plt.xlabel('Channel number')\n",
    "plt.title('maksymalne wartości każdego kanału')\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 224, 224])\n",
      "tensor(8.0764e-06, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "\n",
    "# SNN_input = torch.concat((SNN_input, torch.ones(SNN_input.shape)),dim=1)\n",
    "print(SNN_input.shape)\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "# print(out1)\n",
    "out1_x = model2.conv1(random_input)\n",
    "temp = (conv_first.t_max - out1)*scalar\n",
    "# print((temp[0,:64] - temp[0,64:] - model_conv1).abs().max())\n",
    "print((temp - model_conv1).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9274e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "\n",
    "print(((tmax - out2)*scalar - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "addsnn2 = AddSNNLayer_all(1)\n",
    "addsnn1 = AddSNNLayer_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 2.4999500009761398e-08, mul: 40.00080000038146\n",
      "epsilon: 1.6666333339893902e-08, mul: 60.00120000038148\n",
      "epsilon: 2.499950118354948e-08, mul: 40.00079812224549\n",
      "torch.Size([10, 224, 224])\n",
      "tensor(6.9737e-06)\n",
      "tensor(2.0500, dtype=torch.float64)\n",
      "tensor(2.0500, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:112: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3575.)\n",
      "  V_plus += ((mask_list[i].to(torch.float64).T)@vect).T * duration + ( 0 if self.t_max==self.t_min else ((self.B/(self.multiplier * (self.t_max-self.t_min)))* (min_times[i+1]-min_times[i])) )\n"
     ]
    }
   ],
   "source": [
    "SNN_input1 = 1 - random_input +1\n",
    "SNN_input2 = 1 - random_input +1\n",
    "\n",
    "val_in1, val_in2 = torch.concat((torch.ones(5), torch.zeros(5))),torch.concat((torch.ones(5), torch.zeros(5)))\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2)\n",
    "\n",
    "tmin2, tmax2, val2, scalar2 = addsnn2.set_params(0+1,1+1,val_in1,val_in2,tmax1)\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2,tmax2)\n",
    "\n",
    "outadd1 = addsnn1(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd1.shape)\n",
    "print((((tmax1 - outadd1)[:5] - (tmax1 - outadd1)[5:])*scalar1 - F.relu(random_input*2)).abs().max())# \n",
    "print(tmax1)\n",
    "print(tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(1.0341e-05)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "outadd2 = addsnn2(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd2.shape)\n",
    "print((((tmax1 - outadd2)[:5] - (tmax1 - outadd2)[5:])*scalar2 - F.relu(random_input*2-1)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = SubSNNLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "tmins, tmaxs, sub_val, scalar_sub = sub.set_params(0, tmax1, val1,val2, in_scalar1=scalar1, in_scalar2=scalar2)\n",
    "sub.t_max = tmaxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4782e-05)\n"
     ]
    }
   ],
   "source": [
    "outsub = sub(outadd1,outadd2)\n",
    "print((((sub.t_max-outsub)[:5] - (sub.t_max-outsub)[5:])*scalar_sub - F.hardtanh(random_input*2)).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resblock test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resblocksnn = ResidualSNNBlock_all(model2.layer0[0],64,64, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "epsilon: 1.0801726546521596e-08, mul: 92.57779260501859\n",
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "tensor(1.2489, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2989, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(72.5760, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmin2, tmax2, max_vect2, scalar1 = resblocksnn.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin2, tmax2, scalar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "print(torch.concat((out2, torch.ones(out2.shape) * tmin),dim=1).shape)\n",
    "out3res = resblocksnn(torch.concat((out2, torch.ones(out2.shape) * tmax),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0138, grad_fn=<MaxBackward1>)\n",
      "tensor(2.5541e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out3res)[:64].max())\n",
    "print((((tmax2 - out3res)[:64] - (tmax2 - out3res)[64:])*scalar1  - model_resblock0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2989, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tmax, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.7006065924536695e-08, mul: 21.273850094270706\n",
      "epsilon: 2.422818235295943e-08, mul: 41.27424771003722\n",
      "epsilon: 4.700606813172293e-08, mul: 21.273849095349696\n",
      "tensor(1.5489, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.5989, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn2 = ResidualSNNBlock_all(model2.layer0[1],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn2.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar1)\n",
    "print(tmin2, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out4res = resblocksnn2(out3res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0470, grad_fn=<MaxBackward1>)\n",
      "tensor(2.8074e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out4res)[:64].max())\n",
    "print((((tmax2 - out4res)[:64] - (tmax2 - out4res)[64:])*scalar2  - model_resblock1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.6171308311322e-08, mul: 21.658472254180907\n",
      "epsilon: 2.4004490421596553e-08, mul: 41.658872254180906\n",
      "epsilon: 4.6171310479308016e-08, mul: 21.658471237201653\n",
      "tensor(1.8490, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8990, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn3 = ResidualSNNBlock_all(model2.layer0[2],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn3.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar2)\n",
    "print(tmin2, tmax2)\n",
    "out5res = resblocksnn3(out4res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0462, grad_fn=<MaxBackward1>)\n",
      "tensor(3.1531e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out5res)[:64].max())\n",
    "print((((tmax2 - out5res)[:64] - (tmax2 - out5res)[64:])*scalar2  - model_resblock2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = None\n",
    "\n",
    "# resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy, device='cpu')\n",
    "# tmin, tmax, max_vect = resblockSNN.set_params(0,1, max_vect)\n",
    "# print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "epsilon: 1.0801726546521596e-08, mul: 92.57779260501859\n",
      "epsilon: 1.3778395228969021e-08, mul: 72.57739260501862\n",
      "epsilon: 4.7006065924536695e-08, mul: 21.273850094270706\n",
      "epsilon: 2.422818235295943e-08, mul: 41.27424771003722\n",
      "epsilon: 4.700606813172293e-08, mul: 21.273849095349696\n",
      "epsilon: 4.6171308311322e-08, mul: 21.658472254180907\n",
      "epsilon: 2.4004490421596553e-08, mul: 41.658872254180906\n",
      "epsilon: 4.6171310479308016e-08, mul: 21.658471237201653\n",
      "tensor(1.8490, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8990, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN_all(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmax_prev = tmax\n",
    "tmin, tmax, max_vect,scalar = layer0SNN.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 56, 56])\n",
      "tensor(3.1531e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(torch.concat((out2, torch.ones(out2.shape) * tmax_prev),dim=1))\n",
    "print(out_3.shape)\n",
    "print((((tmax - out_3)[:64] - (tmax - out_3)[64:])*scalar - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.5298376792351925e-08, mul: 65.36641197776794\n",
      "epsilon: 1.1714154210894392e-08, mul: 85.36681197776794\n",
      "epsilon: 1.5298376792351925e-08, mul: 65.36641197776794\n",
      "epsilon: 4.7785949725771944e-08, mul: 20.926653247213363\n",
      "epsilon: 2.4433715827726797e-08, mul: 40.927053709334864\n",
      "epsilon: 4.7785951970007423e-08, mul: 20.926652264406997\n",
      "epsilon: 4.77861620579241e-08, mul: 20.926560262107845\n",
      "epsilon: 2.443377161645323e-08, mul: 40.92696026210785\n",
      "epsilon: 4.77861620579241e-08, mul: 20.926560262107845\n",
      "epsilon: 4.778410414885569e-08, mul: 20.927461502361293\n",
      "epsilon: 2.4433233579582598e-08, mul: 40.927861502361296\n",
      "epsilon: 4.778410414885569e-08, mul: 20.927461502361293\n",
      "tensor(2.9555, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN_all(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer1SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING SubSNNLayer input times not in declared range mismach: 1.1677429938572459e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 1.039013795889332e-06\n",
      "torch.Size([256, 28, 28])\n",
      "tensor(5.8189e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "print((tmax - out_4).shape)\n",
    "print((((tmax - out_4)[ :128] - (tmax - out_4)[ 128:])*scalar - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.207451964294683e-08, mul: 82.81902962360384\n",
      "epsilon: 9.725788701721672e-09, mul: 102.81942479615856\n",
      "epsilon: 1.2074521109483115e-08, mul: 82.8190195646449\n",
      "epsilon: 4.116655734838295e-08, mul: 24.291562482070912\n",
      "epsilon: 2.2577460806045975e-08, mul: 44.29196040204007\n",
      "epsilon: 4.116655928163921e-08, mul: 24.2915613412951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 4.005095500886257e-08, mul: 24.96819363679886\n",
      "epsilon: 2.2237743413506822e-08, mul: 44.968591525011355\n",
      "epsilon: 4.0050959873527274e-08, mul: 24.968190604115236\n",
      "epsilon: 4.441447988043482e-08, mul: 22.515179794788356\n",
      "epsilon: 2.3520790538193057e-08, mul: 42.515577798127154\n",
      "epsilon: 4.44144852751228e-08, mul: 22.51517706004159\n",
      "epsilon: 4.1029323328847575e-08, mul: 24.372812390422816\n",
      "epsilon: 2.2536119116222303e-08, mul: 44.373212390422815\n",
      "epsilon: 4.1029323328847575e-08, mul: 24.372812390422816\n",
      "epsilon: 4.025004498894802e-08, mul: 24.84469272704125\n",
      "epsilon: 2.2298982698524485e-08, mul: 44.845095111274716\n",
      "epsilon: 4.025004498894802e-08, mul: 24.84469272704125\n",
      "tensor(4.6601, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.7101, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN_all(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer2SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print((((tmax - out_5)[:256] - (tmax - out_5)[256:])*scalar - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3822604691.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\2599848737.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.4693848727914322e-08, mul: 68.05568905172349\n",
      "epsilon: 1.1356397457761286e-08, mul: 88.05609382019044\n",
      "epsilon: 1.4693848727914325e-08, mul: 68.05568905172348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\4262345723.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 2.4999500009761398e-08, mul: 40.00080000038146\n",
      "epsilon: 1.6666333339893902e-08, mul: 60.00120000038148\n",
      "epsilon: 2.499950118354948e-08, mul: 40.00079812224549\n",
      "epsilon: 2.4999500009761385e-08, mul: 40.000800000381474\n",
      "tensor(5.2882, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.3382, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN_all(model2.layer3, 256, 512, 3,device = 'cpu',end_maxpool=True)\n",
    "tmin, tmax, max_vect,scalar = layer3SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING SubSNNLayer input times not in declared range mismach: 3.313980414532125e-06\n",
      "WARNING SubSNNLayer input times not in declared range mismach: 5.097710527479649e-06\n",
      "tensor(0.0007, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print((((tmax - out_6)[:512])*scalar - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0006, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6[:512])\n",
    "\n",
    "print(((tmax - out7)*scalar - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3382, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.3882, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(289.2210, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin_, tmax_, max_vect_, scalar_ = spiking_dense.set_params(tmin, tmax, max_vect[:512], in_scalar=scalar)\n",
    "print(tmin_, tmax_, scalar_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "\n",
    "print(((tmax_ - out8)*scalar_ - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(1.1000, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.1119, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.1989, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.2489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.2989, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.3489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.3989, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.4489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.4989, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.5489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.5989, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.6489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.6989, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.7489, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.7990, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.8490, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.8990, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.8990, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.9490, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.9990, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.0055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.0555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.1055, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.1555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.2055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.2555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.3055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.3555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.4055, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.4555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.5055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.5555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.6055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.6555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.7055, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.7555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.8055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.8555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.9055, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.9555, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.0055, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.0055, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.0555, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.1055, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.1100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.1600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.2100, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.2600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.3100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.3600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.4100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.4600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.5100, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.5600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.6100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.6600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.7100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.7600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.8100, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.8600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.9100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.9600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.0100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.0600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.1100, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.1600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.2100, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.2600, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.3101, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.3601, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.4101, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.4601, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.5101, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.5601, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.6101, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.6601, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.7101, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.7101, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.7601, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.8101, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.8117, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.8617, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.9117, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.9617, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.0589, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.0790, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.1290, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.1790, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(5.2290, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.2321, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.2821, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.2882, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.2882, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.3382, dtype=torch.float64, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'czas')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(tt)\n",
    "plt.xlabel(\"Nr. warstwy\")\n",
    "plt.ylabel(\"czas\")\n",
    "# plt.ylim([0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [(tt[i])/(tt[i-1]) for i in range(2,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x178c8262bb0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_positive_tanH(nn.Module):\n",
    "    \"\"\"\n",
    "    from positive to all and Hard tanh\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        b2 = torch.concatenate((biases, -biases)) - 1\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.second = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((input_units,), W.detach().clone(), b1)\n",
    "        self.second.build((input_units,), W.detach().clone(), b2)\n",
    "        self.sub_layer = SubSNNLayer()\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.second.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax2, in_scalar=in_scalar)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub_layer.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2) ## t_min as angument do nothing\n",
    "        self.sub_layer.t_max = min(tmaxs,tmins+(1/in_scalar_sub))+eps_V\n",
    "        return tmins, min(tmaxs,tmins+(1/in_scalar_sub))+eps_V, torch.maximum(sub_val, 1/in_scalar_sub), in_scalar_sub\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        out2 = self.second(tj)\n",
    "        sub_ = self.sub_layer(out1,out2)\n",
    "        return sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "input_ttfs = out7.view(out7.size(0), -1)\n",
    "input_x = (tmax - input_ttfs)*scalar\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "scalar__ = scalar\n",
    "max_vect__ = max_vect\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model2.fc.weight.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "\n",
    "layer = SpikingDense_positive_tanH(10,512, '',weights, biases,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3882, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.3916, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(294.8974, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\3349878124.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer.set_params(t_min__, t_max__, max_vect__[:512], in_scalar=scalar__)\n",
    "print(t_min, t_max, scalar___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - F.hardtanh(out_x)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_all_all(nn.Module):\n",
    "    \"\"\"\n",
    "    from all to all (pure linear layer)\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W1 = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        W2 = torch.concatenate((-weights.T, weights.T),dim=1)\n",
    "        W = torch.concatenate((W1,W2),dim=0)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((2*input_units,), W, b1)\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin1, tmax1, first_val, in_scalar\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sh = list(input_ttfs.shape)\n",
    "sh[1] = sh[1]\n",
    "binary_mask = torch.randint(0,2,sh)\n",
    "binary_mask = torch.concat((binary_mask, 1-binary_mask),dim=1)\n",
    "sh[1] = sh[1]*2\n",
    "\n",
    "input_ttfs = (torch.rand(sh)*(tmax - tmin) + tmin) * binary_mask\n",
    "input_x = ((tmax - input_ttfs[0,:512]) - (tmax - input_ttfs[0,512:]))*scalar__\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "max_vect__ = torch.rand(1024)\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)\n",
    "print(input_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = SpikingDense_all_all(10,512, '',model2.fc.weight, model2.fc.bias,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_22260\\1511855879.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer2.set_params(t_min__, t_max__, max_vect__, scalar__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0028, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer2.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - out_x).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3882, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
