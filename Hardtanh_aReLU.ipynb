{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn.functional as F\n",
    "\n",
    "L = 20 # multiplier coef\n",
    "eps = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, end_maxpool = False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        if self.end_maxpool:\n",
    "            out = F.relu(out, inplace=False)\n",
    "        else:\n",
    "            out = F.hardtanh(out, inplace=False, min_val=-1.0, max_val=1.0)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2, end_maxpool = True)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, end_maxpool = False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                layers.append(block(self.inplanes, planes, end_maxpool = True))\n",
    "            else:\n",
    "                layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_Hardtanh_ReLUmaxpool.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na ISNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.multiplier = 1\n",
    "        self.mul = 1\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.W = kernel.clone()\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.W = kernel.clone()\n",
    "                self.B = bias.clone().unsqueeze(0)\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1 ):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), self.B))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.W * in_scalar,torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.B, torch.zeros(self.B.shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel*in_scalar,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        \n",
    "        if self.bias:\n",
    "            self.kernel = nn.Parameter(torch.concat((self.W.clone()*(in_scalar/(self.multiplier)),self.B.clone()/(self.multiplier))))\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(self.W.clone()*(in_scalar/(self.multiplier)))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), self.kernel[-1].unsqueeze(0)))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1], torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.kernel[-1].unsqueeze(0), torch.zeros(self.kernel[-1].unsqueeze(0).shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel*(in_scalar),torch.zeros(self.kernel.shape).to(self.device))\n",
    "        # print(max_W.shape)\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        # print(max_input.shape)\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))))\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "            \n",
    "            print(self.multiplier)\n",
    "        else:\n",
    "            if minimal_t_max-self.t_min==0:\n",
    "                self.multiplier = (self.t_max - self.t_min)+eps\n",
    "            else:\n",
    "                self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "            print(self.multiplier, self.t_max , self.t_min, minimal_t_max)\n",
    "        self.kernel_mul = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_W = torch.maximum(self.kernel*self.kernel_mul,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        # print(max_W.shape)\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        # print(max_input.shape)\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)/self.multiplier)\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))/self.multiplier))\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), max_values, self.multiplier\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # Wyciąganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "\n",
    "            ti = self.call_spiking(tj, W * self.kernel_mul, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W * self.kernel_mul,self.B.T / self.multiplier),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul1\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj1*self.mul1 + tj2*self.mul2 - (self.mul1+self.mul2)*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.multiplier = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        output_val = input1_val*in_scalar1\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = (tj1 - self.t_min)*self.mul1 - (tj2 - self.t_min)*self.mul2  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \n",
    "        max_input = max(in_ranges_max*in_scalar)\n",
    "        max_V = max_input\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min)/(max(minimal_t_max-self.t_min,1.0/L))+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar,L)\n",
    "        self.mul1 = (in_scalar/(self.multiplier))\n",
    "\n",
    "        max_input = max(in_ranges_max*self.mul1)\n",
    "        max_V = max_input\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), in_ranges_max, self.multiplier\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = (tj - self.t_min)*self.mul1  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar = in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2  = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_resblock0 = model2.layer0[0](model_maxpool)\n",
    "model_resblock1 = model2.layer0[1](model_resblock0)\n",
    "model_resblock2 = model2.layer0[2](model_resblock1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_Htanh(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_Htanh, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        \n",
    "        kernels_neg = torch.concat((-kernels,kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_neg = -biases\n",
    "        else:\n",
    "            biases_neg = None\n",
    "\n",
    "        kernels_new = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new = torch.concat((biases_pos, biases_neg))\n",
    "        print(biases_new.shape)\n",
    "        self.conv_first = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "        \n",
    "        kernels_new2 = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new2 = torch.concat((biases_pos, biases_neg)) - 1\n",
    "        self.conv_second = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new2, biases=biases_new2)\n",
    "        self.sub = SubSNNLayer()\n",
    "        self.filters = filters*2\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        if(in_ranges_max.shape[0] != self.filters):\n",
    "            in_ranges_max = torch.concat((in_ranges_max,torch.zeros(in_ranges_max.shape)))\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.conv_second.set_params(t_min_prev, t_min, in_ranges_max, tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, tmax2, in_scalar=in_scalar)\n",
    "        self.t_max = tmax1\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        tmaxs = max(min(tmaxs,tmins+1.0/in_scalar_sub), minimal_t_max)\n",
    "        self.sub.t_max = tmaxs\n",
    "        self.t_max = tmaxs\n",
    "        # Returning for function signature consistency\n",
    "        return tmins, self.t_max, torch.minimum(sub_val, torch.ones(sub_val.shape)/in_scalar_sub), in_scalar_sub\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        tj2 = self.conv_second(tj)\n",
    "        tj_sub = self.sub(tj1, tj2)\n",
    "\n",
    "        return tj_sub\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_all(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, bias=0):\n",
    "        super(AddSNNLayer_all, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.B = bias # bias for all inputs (for Hard tanh)\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        if input2_val.shape[0] != input1_val.shape[0]:\n",
    "            input2_val = torch.concat((input2_val, torch.zeros(input2_val.shape)))\n",
    "        output_val = input1_val*in_scalar1 + input2_val*in_scalar2 + self.B\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        if(minimal_t_max == 0):\n",
    "            self.multiplier = self.t_max - self.t_min\n",
    "            self.multiplier = self.multiplier*L+eps\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "            \n",
    "        else:\n",
    "            self.multiplier = (self.t_max - self.t_min + eps)/(max(minimal_t_max-self.t_min,1.0/L))\n",
    "            if self.multiplier==0:\n",
    "                self.multiplier=max(L*in_scalar1,L,L*in_scalar2)\n",
    "        self.mul1 = (in_scalar1/(self.multiplier))\n",
    "        self.mul2 = (in_scalar2/(self.multiplier))\n",
    "\n",
    "        output_val = input1_val*self.mul1 + input2_val*self.mul2 + self.B/self.multiplier\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val, self.multiplier\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "\n",
    "        self.channels = tj1.shape[1]//2\n",
    "\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = torch.concat(((tj1[0, :self.channels]- tj1[0, self.channels:])*self.mul1 + (tj2[0, :self.channels]  - tj2[0, self.channels:])*self.mul2, \n",
    "                           (tj1[0, self.channels:] - tj1[0, :self.channels])*self.mul1 + (tj2[0, self.channels:] - tj2[0, :self.channels])*self.mul2)) + self.B/(self.multiplier)*(1) + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_Htanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer_Htanh, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.first = AddSNNLayer_all()\n",
    "        self.second = AddSNNLayer_all(1)\n",
    "        self.sub = SubSNNLayer()\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0, in_scalar1 = 1, in_scalar2 = 1):\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "        tmin2, tmax2, second_val, in_scalar_second = self.second.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax1, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar_first = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax2, in_scalar1=in_scalar1, in_scalar2=in_scalar2)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar_first, in_scalar2=in_scalar_second) ## t_min as angument do nothing\n",
    "        self.sub.t_max = max(tmins+(1.0/in_scalar_sub), minimal_t_max)\n",
    "        return tmins, max(tmins+(1.0/in_scalar_sub), minimal_t_max), torch.minimum(sub_val,(1.0/in_scalar_sub)), in_scalar_sub\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        tj_first = self.first(tj1, tj2)\n",
    "        tj_second = self.second(tj1, tj2)\n",
    "        tj_sub = self.sub(tj_first, tj_second)\n",
    "        return tj_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_all(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_all, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        kernels_new = kernels_pos\n",
    "        biases_new = biases_pos\n",
    "        self.conv_first = SpikingConv2D(filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, out_scalar = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, in_scalar = in_scalar)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return tmin1, tmax1, first_val, out_scalar\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        return tj1\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock_all(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\", end_maxpool = False):\n",
    "        super(ResidualSNNBlock_all, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        if (downsample is not None):\n",
    "            self.conv1 = SpikingConv2D_all(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        else:\n",
    "            self.conv1 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        if end_maxpool:\n",
    "            self.add_layer = AddSNNLayer_all()\n",
    "        else:\n",
    "            self.add_layer = AddSNNLayer_Htanh()\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0, in_scalar = 1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val, in_scalar1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "        self.t_max1 = t_max1\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            self.t_max1_dummy = t_max1_dummy\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val, in_scalar_downsample = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val, in_scalar=in_scalar)\n",
    "\n",
    "        t_min2, t_max2, conv2_val, in_scalar2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val, in_scalar=in_scalar1)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val, out_scalar = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val, in_scalar1=in_scalar2, in_scalar2=in_scalar_downsample)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val, out_scalar\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "            residual = torch.concat((residual,torch.ones(residual.shape)*self.t_max1_dummy), dim=1)\n",
    "            out = torch.concat((out,torch.ones(out.shape)*self.t_max1), dim=1)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual) # no need for adding negative part\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN_all(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0', end_maxpool = False):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D_all(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock_all(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device, end_maxpool = True))\n",
    "            else:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0, in_scalar = 1):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max, in_scalar = self.layers[i].set_params(tmin, tmax,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin, tmax, in_ranges_max, in_scalar\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            print(i)\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(71.1717, dtype=torch.float64)\n",
      "1 tensor(1.0500, grad_fn=<AddBackward0>) tensor(71.1717, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "max_vect = torch.tensor([1,1,1,1,1])\n",
    "tmin, tmax, max_vect, scalar = conv_first.set_params(0,1,max_vect)\n",
    "print(tmin, tmax, scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "print(model_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9775e-06, 0.0000e+00, 9.1083e-04, 3.9515e-04, 0.0000e+00, 1.4991e-02,\n",
      "        4.9621e-09, 0.0000e+00, 2.6293e-05, 0.0000e+00, 2.2074e-07, 8.0345e-07,\n",
      "        2.4908e-08, 2.7611e-07, 0.0000e+00, 2.0023e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.0948e-04, 0.0000e+00, 4.5383e-04, 2.2796e-02,\n",
      "        0.0000e+00, 5.1981e-04, 7.9895e-04, 1.6889e-08, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.0456e-08, 0.0000e+00, 1.2533e-04, 0.0000e+00,\n",
      "        2.1487e-04, 0.0000e+00, 6.5975e-04, 0.0000e+00, 7.5714e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1994e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2233e-07, 5.3934e-05, 7.6377e-04,\n",
      "        0.0000e+00, 0.0000e+00, 8.0127e-05, 2.0703e-02],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tworzenie przykładowego array'a\n",
    "values = max_vect.detach().numpy()\n",
    "labels = [ i for i in range(len(max_vect))]\n",
    "\n",
    "# Tworzenie wykresu słupkowego\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "\n",
    "# Dodanie etykiet\n",
    "plt.ylabel('$x_{max}$')\n",
    "plt.xlabel('Channel number')\n",
    "plt.title('maksymalne wartości każdego kanału')\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 224, 224])\n",
      "tensor(4.9472e-06, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "\n",
    "# SNN_input = torch.concat((SNN_input, torch.ones(SNN_input.shape)),dim=1)\n",
    "print(SNN_input.shape)\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "# print(out1)\n",
    "out1_x = model2.conv1(random_input)\n",
    "temp = (conv_first.t_max - out1)*scalar\n",
    "# print((temp[0,:64] - temp[0,64:] - model_conv1).abs().max())\n",
    "print((temp - model_conv1).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9472e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "\n",
    "print(((tmax - out2)*scalar - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "addsnn2 = AddSNNLayer_all(1)\n",
    "addsnn1 = AddSNNLayer_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(4.8876e-06)\n",
      "tensor(2.0500)\n",
      "tensor(2.0500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "SNN_input1 = 1 - random_input +1\n",
    "SNN_input2 = 1 - random_input +1\n",
    "\n",
    "val_in1, val_in2 = torch.concat((torch.ones(5), torch.zeros(5))),torch.concat((torch.ones(5), torch.zeros(5)))\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2)\n",
    "\n",
    "tmin2, tmax2, val2, scalar2 = addsnn2.set_params(0+1,1+1,val_in1,val_in2,tmax1)\n",
    "tmin1, tmax1, val1, scalar1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2,tmax2)\n",
    "\n",
    "outadd1 = addsnn1(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd1.shape)\n",
    "print((((tmax1 - outadd1)[:5] - (tmax1 - outadd1)[5:])*scalar1 - F.relu(random_input*2)).abs().max())# \n",
    "print(tmax1)\n",
    "print(tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(7.3910e-06)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "outadd2 = addsnn2(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd2.shape)\n",
    "print((((tmax1 - outadd2)[:5] - (tmax1 - outadd2)[5:])*scalar2 - F.relu(random_input*2-1)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = SubSNNLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "tmins, tmaxs, sub_val, scalar_sub = sub.set_params(0, tmax1, val1,val2, in_scalar1=scalar1, in_scalar2=scalar2)\n",
    "sub.t_max = tmins+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3471e-05)\n"
     ]
    }
   ],
   "source": [
    "outsub = sub(outadd1,outadd2)\n",
    "print((((sub.t_max-outsub)[:5] - (sub.t_max-outsub)[5:])*scalar_sub - F.hardtanh(random_input*2)).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resblock test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "resblocksnn = ResidualSNNBlock_all(model2.layer0[0],64,64, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87.0628, dtype=torch.float64)\n",
      "tensor(87.0628, dtype=torch.float64) tensor(5.4031, dtype=torch.float64) tensor(1.0500, dtype=torch.float64) tensor(1.1000, grad_fn=<AddBackward0>)\n",
      "tensor(87.0628, dtype=torch.float64) tensor(5.4031, dtype=torch.float64) tensor(1.0500, dtype=torch.float64) tensor(1.1000, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64)\n",
      "tensor(26.7132, dtype=torch.float64) tensor(2.4476, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.4633, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64)\n",
      "tensor(26.7132, dtype=torch.float64) tensor(2.4476, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.4633, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2489, grad_fn=<AddBackward0>) tensor(1.2848, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(27.9015, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmin2, tmax2, max_vect2, scalar1 = resblocksnn.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin2, tmax2, scalar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "print(torch.concat((out2, torch.ones(out2.shape) * tmin),dim=1).shape)\n",
    "out3res = resblocksnn(torch.concat((out2, torch.ones(out2.shape) * tmax),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0358, grad_fn=<MaxBackward1>)\n",
      "tensor(1.3828e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out3res)[:64].max())\n",
    "print((((tmax2 - out3res)[:64] - (tmax2 - out3res)[64:])*scalar1  - model_resblock0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0500, grad_fn=<AddBackward0>) tensor(1.2848, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tmax, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0018, dtype=torch.float64)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2848, dtype=torch.float64) tensor(1.2848, dtype=torch.float64) tensor(1.3348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2849, dtype=torch.float64) tensor(1.2848, dtype=torch.float64) tensor(1.3348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64)\n",
      "tensor(1.2281e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3848, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.4485, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64)\n",
      "tensor(1.2281e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3848, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.4485, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5348, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.7407, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn2 = ResidualSNNBlock_all(model2.layer0[1],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn2.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar1)\n",
    "print(tmin2, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "out4res = resblocksnn2(out3res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2059, grad_fn=<MaxBackward1>)\n",
      "tensor(1.4424e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out4res)[:64].max())\n",
    "print((((tmax2 - out4res)[:64] - (tmax2 - out4res)[64:])*scalar2  - model_resblock1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "tensor(0.5770, dtype=torch.float64)\n",
      "tensor(0.5770, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.7695, dtype=torch.float64) tensor(1.7407, dtype=torch.float64) tensor(1.7907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.5770, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.7695, dtype=torch.float64) tensor(1.7407, dtype=torch.float64) tensor(1.7907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64)\n",
      "tensor(0.3245, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8569, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9134, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64)\n",
      "tensor(0.3245, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8569, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9134, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9907, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.3653, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "resblocksnn3 = ResidualSNNBlock_all(model2.layer0[2],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2, scalar2 = resblocksnn3.set_params(tmin2, tmax2, max_vect2, in_scalar=scalar2)\n",
    "print(tmin2, tmax2)\n",
    "out5res = resblocksnn3(out4res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3747, grad_fn=<MaxBackward1>)\n",
      "tensor(1.4663e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out5res)[:64].max())\n",
    "print((((tmax2 - out5res)[:64] - (tmax2 - out5res)[64:])*scalar2  - model_resblock2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = None\n",
    "\n",
    "# resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy, device='cpu')\n",
    "# tmin, tmax, max_vect = resblockSNN.set_params(0,1, max_vect)\n",
    "# print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "tensor(87.0628, dtype=torch.float64)\n",
      "tensor(87.0628, dtype=torch.float64) tensor(5.4031, dtype=torch.float64) tensor(1.0500, dtype=torch.float64) tensor(1.1000, grad_fn=<AddBackward0>)\n",
      "tensor(87.0628, dtype=torch.float64) tensor(5.4031, dtype=torch.float64) tensor(1.0500, dtype=torch.float64) tensor(1.1000, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64)\n",
      "tensor(26.7132, dtype=torch.float64) tensor(2.4476, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.4633, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64)\n",
      "tensor(26.7132, dtype=torch.float64) tensor(2.4476, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.0278, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.4633, dtype=torch.float64) tensor(1.1119, dtype=torch.float64) tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, dtype=torch.float64)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2848, dtype=torch.float64) tensor(1.2848, dtype=torch.float64) tensor(1.3348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.2849, dtype=torch.float64) tensor(1.2848, dtype=torch.float64) tensor(1.3348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64)\n",
      "tensor(1.2281e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3848, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.4485, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2734, dtype=torch.float64)\n",
      "tensor(1.2281e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.3848, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.2734, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.4485, dtype=torch.float64) tensor(1.3848, dtype=torch.float64) tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.5770, dtype=torch.float64)\n",
      "tensor(0.5770, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.7695, dtype=torch.float64) tensor(1.7407, dtype=torch.float64) tensor(1.7907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.5770, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.7695, dtype=torch.float64) tensor(1.7407, dtype=torch.float64) tensor(1.7907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64)\n",
      "tensor(0.3245, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8569, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9134, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64)\n",
      "tensor(0.3245, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.8569, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4545, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.9134, dtype=torch.float64) tensor(1.8407, dtype=torch.float64) tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9907, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.3653, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN_all(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmax_prev = tmax\n",
    "tmin, tmax, max_vect,scalar = layer0SNN.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))), in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 128, 56, 56])\n",
      "1\n",
      "torch.Size([1, 128, 56, 56])\n",
      "2\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([128, 56, 56])\n",
      "tensor(1.4663e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(torch.concat((out2, torch.ones(out2.shape) * tmax_prev),dim=1))\n",
    "print(out_3.shape)\n",
    "print((((tmax - out_3)[:64] - (tmax - out_3)[64:])*scalar - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "tensor(3.8750, dtype=torch.float64)\n",
      "tensor(6.8345, dtype=torch.float64)\n",
      "tensor(5.7545, dtype=torch.float64) tensor(2.7031, dtype=torch.float64) tensor(2.4153, dtype=torch.float64) tensor(2.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.8345, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.7571, dtype=torch.float64) tensor(2.4153, dtype=torch.float64) tensor(2.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.2153, dtype=torch.float64)\n",
      "tensor(4.2153, dtype=torch.float64)\n",
      "tensor(6.8345, dtype=torch.float64)\n",
      "tensor(5.7545, dtype=torch.float64) tensor(2.7031, dtype=torch.float64) tensor(2.4153, dtype=torch.float64) tensor(2.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.8345, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.7571, dtype=torch.float64) tensor(2.4153, dtype=torch.float64) tensor(2.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, dtype=torch.float64)\n",
      "tensor(0.0001, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.6993, dtype=torch.float64) tensor(2.6993, dtype=torch.float64) tensor(2.7493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.6993, dtype=torch.float64) tensor(2.6993, dtype=torch.float64) tensor(2.7493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9262, dtype=torch.float64)\n",
      "tensor(1.3973e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.7993, dtype=torch.float64) tensor(2.7993, dtype=torch.float64) tensor(2.8493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9262, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.8456, dtype=torch.float64) tensor(2.7993, dtype=torch.float64) tensor(2.8493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9262, dtype=torch.float64)\n",
      "tensor(1.3973e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.7993, dtype=torch.float64) tensor(2.7993, dtype=torch.float64) tensor(2.8493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9262, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.8456, dtype=torch.float64) tensor(2.7993, dtype=torch.float64) tensor(2.8493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, dtype=torch.float64)\n",
      "tensor(4.8786e-05, dtype=torch.float64) tensor(3.4849, dtype=torch.float64) tensor(3.4849, dtype=torch.float64) tensor(3.5349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.4850, dtype=torch.float64) tensor(3.4849, dtype=torch.float64) tensor(3.5349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9261, dtype=torch.float64)\n",
      "tensor(2.1115e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.5849, dtype=torch.float64) tensor(3.5849, dtype=torch.float64) tensor(3.6349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9261, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.6312, dtype=torch.float64) tensor(3.5849, dtype=torch.float64) tensor(3.6349, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9261, dtype=torch.float64)\n",
      "tensor(2.1115e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.5849, dtype=torch.float64) tensor(3.5849, dtype=torch.float64) tensor(3.6349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9261, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(3.6312, dtype=torch.float64) tensor(3.5849, dtype=torch.float64) tensor(3.6349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, dtype=torch.float64)\n",
      "tensor(3.4711e-05, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.4727, dtype=torch.float64) tensor(4.4727, dtype=torch.float64) tensor(4.5227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.4728, dtype=torch.float64) tensor(4.4727, dtype=torch.float64) tensor(4.5227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9270, dtype=torch.float64)\n",
      "tensor(3.8935e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.5727, dtype=torch.float64) tensor(4.5727, dtype=torch.float64) tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9270, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.6191, dtype=torch.float64) tensor(4.5727, dtype=torch.float64) tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9270, dtype=torch.float64)\n",
      "tensor(3.8935e-09, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.5727, dtype=torch.float64) tensor(4.5727, dtype=torch.float64) tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.9270, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(4.6191, dtype=torch.float64) tensor(4.5727, dtype=torch.float64) tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7227, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.5259, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN_all(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer1SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 256, 28, 28])\n",
      "1\n",
      "torch.Size([1, 256, 28, 28])\n",
      "2\n",
      "torch.Size([1, 256, 28, 28])\n",
      "3\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([256, 28, 28])\n",
      "tensor(1.3597e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "print((tmax - out_4).shape)\n",
    "print((((tmax - out_4)[ :128] - (tmax - out_4)[ 128:])*scalar - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "tensor(2.8963, dtype=torch.float64)\n",
      "tensor(6.7007, dtype=torch.float64)\n",
      "tensor(1.8287, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.6673, dtype=torch.float64) tensor(5.5759, dtype=torch.float64) tensor(5.6259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.7007, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.9109, dtype=torch.float64) tensor(5.5759, dtype=torch.float64) tensor(5.6259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9411, dtype=torch.float64)\n",
      "tensor(1.9411, dtype=torch.float64)\n",
      "tensor(6.7007, dtype=torch.float64)\n",
      "tensor(1.8287, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.6673, dtype=torch.float64) tensor(5.5759, dtype=torch.float64) tensor(5.6259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.7007, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.9109, dtype=torch.float64) tensor(5.5759, dtype=torch.float64) tensor(5.6259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.6465, dtype=torch.float64)\n",
      "tensor(0.5639, dtype=torch.float64) tensor(5.9033, dtype=torch.float64) tensor(5.8751, dtype=torch.float64) tensor(5.9251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.6465, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.9074, dtype=torch.float64) tensor(5.8751, dtype=torch.float64) tensor(5.9251, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0127, dtype=torch.float64)\n",
      "tensor(0.4896, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.9996, dtype=torch.float64) tensor(5.9751, dtype=torch.float64) tensor(6.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0127, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(6.0757, dtype=torch.float64) tensor(5.9751, dtype=torch.float64) tensor(6.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0127, dtype=torch.float64)\n",
      "tensor(0.4896, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(5.9996, dtype=torch.float64) tensor(5.9751, dtype=torch.float64) tensor(6.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0127, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(6.0757, dtype=torch.float64) tensor(5.9751, dtype=torch.float64) tensor(6.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.4298, dtype=torch.float64)\n",
      "tensor(0.2926, dtype=torch.float64) tensor(6.4707, dtype=torch.float64) tensor(6.4561, dtype=torch.float64) tensor(6.5061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.4298, dtype=torch.float64) tensor(6.4776, dtype=torch.float64) tensor(6.4561, dtype=torch.float64) tensor(6.5061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1121, dtype=torch.float64)\n",
      "tensor(0.3792, dtype=torch.float64) tensor(6.5751, dtype=torch.float64) tensor(6.5561, dtype=torch.float64) tensor(6.6061, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1121, dtype=torch.float64) tensor(6.6617, dtype=torch.float64) tensor(6.5561, dtype=torch.float64) tensor(6.6061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1121, dtype=torch.float64)\n",
      "tensor(0.3792, dtype=torch.float64) tensor(6.5751, dtype=torch.float64) tensor(6.5561, dtype=torch.float64) tensor(6.6061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1121, dtype=torch.float64) tensor(6.6617, dtype=torch.float64) tensor(6.5561, dtype=torch.float64) tensor(6.6061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.4337, dtype=torch.float64)\n",
      "tensor(0.1749, dtype=torch.float64) tensor(7.0636, dtype=torch.float64) tensor(7.0548, dtype=torch.float64) tensor(7.1048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.4337, dtype=torch.float64) tensor(7.0765, dtype=torch.float64) tensor(7.0548, dtype=torch.float64) tensor(7.1048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8403, dtype=torch.float64)\n",
      "tensor(0.3372, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.1717, dtype=torch.float64) tensor(7.1548, dtype=torch.float64) tensor(7.2048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8403, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.2469, dtype=torch.float64) tensor(7.1548, dtype=torch.float64) tensor(7.2048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8403, dtype=torch.float64)\n",
      "tensor(0.3372, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.1717, dtype=torch.float64) tensor(7.1548, dtype=torch.float64) tensor(7.2048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8403, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.2469, dtype=torch.float64) tensor(7.1548, dtype=torch.float64) tensor(7.2048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.6343, dtype=torch.float64)\n",
      "tensor(0.1966, dtype=torch.float64) tensor(7.7057, dtype=torch.float64) tensor(7.6959, dtype=torch.float64) tensor(7.7459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.6343, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.7276, dtype=torch.float64) tensor(7.6959, dtype=torch.float64) tensor(7.7459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8029, dtype=torch.float64)\n",
      "tensor(0.4508, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.8184, dtype=torch.float64) tensor(7.7959, dtype=torch.float64) tensor(7.8459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8029, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.8860, dtype=torch.float64) tensor(7.7959, dtype=torch.float64) tensor(7.8459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8029, dtype=torch.float64)\n",
      "tensor(0.4508, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.8184, dtype=torch.float64) tensor(7.7959, dtype=torch.float64) tensor(7.8459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8029, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(7.8860, dtype=torch.float64) tensor(7.7959, dtype=torch.float64) tensor(7.8459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.5612, dtype=torch.float64)\n",
      "tensor(0.2011, dtype=torch.float64) tensor(8.3654, dtype=torch.float64) tensor(8.3554, dtype=torch.float64) tensor(8.4054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(0.5612, dtype=torch.float64) tensor(8.3834, dtype=torch.float64) tensor(8.3554, dtype=torch.float64) tensor(8.4054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7905, dtype=torch.float64)\n",
      "tensor(0.4695, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(8.4788, dtype=torch.float64) tensor(8.4554, dtype=torch.float64) tensor(8.5054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7905, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(8.5449, dtype=torch.float64) tensor(8.4554, dtype=torch.float64) tensor(8.5054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7905, dtype=torch.float64)\n",
      "tensor(0.4695, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(8.4788, dtype=torch.float64) tensor(8.4554, dtype=torch.float64) tensor(8.5054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7905, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(8.5449, dtype=torch.float64) tensor(8.4554, dtype=torch.float64) tensor(8.5054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.6054, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN_all(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax, max_vect,scalar = layer2SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 512, 14, 14])\n",
      "1\n",
      "torch.Size([1, 512, 14, 14])\n",
      "2\n",
      "torch.Size([1, 512, 14, 14])\n",
      "3\n",
      "torch.Size([1, 512, 14, 14])\n",
      "4\n",
      "torch.Size([1, 512, 14, 14])\n",
      "5\n",
      "torch.Size([1, 512, 14, 14])\n",
      "tensor(1.5765e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print((((tmax - out_5)[:256] - (tmax - out_5)[256:])*scalar - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "tensor(9.2031, dtype=torch.float64)\n",
      "tensor(16.4800, dtype=torch.float64)\n",
      "tensor(16.4800, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8958, dtype=torch.float64) tensor(9.0718, dtype=torch.float64) tensor(9.1218, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1164209833.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.4800, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8958, dtype=torch.float64) tensor(9.0718, dtype=torch.float64) tensor(9.1218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6277, dtype=torch.float64)\n",
      "tensor(1.6277, dtype=torch.float64)\n",
      "tensor(16.4800, dtype=torch.float64)\n",
      "tensor(16.4800, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8958, dtype=torch.float64) tensor(9.0718, dtype=torch.float64) tensor(9.1218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(16.4800, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8958, dtype=torch.float64) tensor(9.0718, dtype=torch.float64) tensor(9.1218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.3779, dtype=torch.float64)\n",
      "tensor(7.3779, dtype=torch.float64) tensor(9.6541, dtype=torch.float64) tensor(9.2852, dtype=torch.float64) tensor(9.3352, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3733583538.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3779, dtype=torch.float64) tensor(9.6541, dtype=torch.float64) tensor(9.2852, dtype=torch.float64) tensor(9.3352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.8167, dtype=torch.float64)\n",
      "tensor(14.8167, dtype=torch.float64) tensor(10.1261, dtype=torch.float64) tensor(9.3852, dtype=torch.float64) tensor(9.4352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.8167, dtype=torch.float64) tensor(10.1261, dtype=torch.float64) tensor(9.3852, dtype=torch.float64) tensor(9.4352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.8167, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\2175750539.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.8167, dtype=torch.float64) tensor(10.1261, dtype=torch.float64) tensor(9.3852, dtype=torch.float64) tensor(9.4352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.8167, dtype=torch.float64) tensor(10.1261, dtype=torch.float64) tensor(9.3852, dtype=torch.float64) tensor(9.4352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(62.2968, dtype=torch.float64)\n",
      "tensor(62.2968, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(12.7184, dtype=torch.float64) tensor(9.6036, dtype=torch.float64) tensor(9.6536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(62.2968, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(12.7184, dtype=torch.float64) tensor(9.6036, dtype=torch.float64) tensor(9.6536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(120.0343, dtype=torch.float64)\n",
      "tensor(119.4886, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(15.6449, dtype=torch.float64) tensor(9.6705, dtype=torch.float64) tensor(9.7205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(120.0343, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(15.6722, dtype=torch.float64) tensor(9.6705, dtype=torch.float64) tensor(9.7205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(120.0343, dtype=torch.float64)\n",
      "tensor(119.4886, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(15.6449, dtype=torch.float64) tensor(9.6705, dtype=torch.float64) tensor(9.7205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(120.0343, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(15.6722, dtype=torch.float64) tensor(9.6705, dtype=torch.float64) tensor(9.7205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.7288, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.7788, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN_all(model2.layer3, 256, 512, 3,device = 'cpu',end_maxpool=True)\n",
    "tmin, tmax, max_vect,scalar = layer3SNN.set_params(tmin, tmax, max_vect, in_scalar=scalar)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "1\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "2\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print((((tmax - out_6)[:512])*scalar - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6[:512])\n",
    "\n",
    "print(((tmax - out7)*scalar - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.7788, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8288, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(149.1559, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin_, tmax_, max_vect_, scalar_ = spiking_dense.set_params(tmin, tmax, max_vect[:512], in_scalar=scalar)\n",
    "print(tmin_, tmax_, scalar_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "\n",
    "print(((tmax_ - out8)*scalar_ - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(1.1000, grad_fn=<AddBackward0>), tensor(1.1119, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.1619, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.1989, grad_fn=<AddBackward0>), 'c'), (tensor(1.2489, grad_fn=<AddBackward0>), tensor(1.2848, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.3348, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.3848, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.4348, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.4848, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.5348, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.7407, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(1.7907, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.8407, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.8907, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(1.9407, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(1.9907, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.3653, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.3653, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.4153, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.4653, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.5153, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.5653, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.6993, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(2.7493, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.7993, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.8493, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2.8993, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(2.9493, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.4849, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(3.5349, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.5849, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.6349, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3.6849, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(3.7349, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.4727, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(4.5227, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.5727, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(4.6727, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(4.7227, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.5259, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(5.5259, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.5759, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.6259, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.6759, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(5.7259, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.8751, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(5.9251, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(5.9751, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(6.0251, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(6.0751, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(6.1251, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(6.4561, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(6.5061, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(6.5561, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(6.6061, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(6.6561, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(6.7061, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.0548, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(7.1048, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.1548, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(7.2048, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.2548, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(7.3048, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.6959, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(7.7459, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.7959, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(7.8459, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(7.8959, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(7.9459, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(8.3554, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(8.4054, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(8.4554, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(8.5054, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(8.5554, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(8.6054, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.0218, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(9.0218, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.0718, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.1218, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.1718, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.2218, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.2852, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(9.3352, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.3852, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.4352, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.4852, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.5352, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.6036, dtype=torch.float64, grad_fn=<AddBackward0>), 'a'), (tensor(9.6536, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.6705, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.7205, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.7288, dtype=torch.float64, grad_fn=<AddBackward0>), 'c'), (tensor(9.7288, dtype=torch.float64, grad_fn=<AddBackward0>), tensor(9.7788, dtype=torch.float64, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'czas')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(tt)\n",
    "plt.xlabel(\"Nr. warstwy\")\n",
    "plt.ylabel(\"czas\")\n",
    "# plt.ylim([0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [(tt[i])/(tt[i-1]) for i in range(2,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae493ccb50>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_positive_tanH(nn.Module):\n",
    "    \"\"\"\n",
    "    from positive to all and Hard tanh\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        b2 = torch.concatenate((biases, -biases)) - 1\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.second = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((input_units,), W.detach().clone(), b1)\n",
    "        self.second.build((input_units,), W.detach().clone(), b2)\n",
    "        self.sub_layer = SubSNNLayer()\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        tmin2, tmax2, second_val, in_scalar2 = self.second.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax1, in_scalar=in_scalar)\n",
    "\n",
    "        tmin1, tmax1, first_val, in_scalar1 = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax2, in_scalar=in_scalar)\n",
    "\n",
    "        tmins, tmaxs, sub_val, in_scalar_sub = self.sub_layer.set_params(t_min, tmax1, first_val,second_val, in_scalar1=in_scalar1, in_scalar2=in_scalar2) ## t_min as angument do nothing\n",
    "        self.sub_layer.t_max = min(tmaxs,tmins+(1/in_scalar_sub))\n",
    "        return tmins, min(tmaxs,tmins+(1/in_scalar_sub)), torch.maximum(sub_val, 1/in_scalar_sub), in_scalar_sub\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        out2 = self.second(tj)\n",
    "        sub_ = self.sub_layer(out1,out2)\n",
    "        return sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "input_ttfs = out7.view(out7.size(0), -1)\n",
    "input_x = (tmax - input_ttfs)*scalar\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "scalar__ = scalar\n",
    "max_vect__ = max_vect\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model2.fc.weight.detach().clone()\n",
    "biases = model2.fc.bias.detach().clone()\n",
    "\n",
    "layer = SpikingDense_positive_tanH(10,512, '',weights, biases,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8288, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(9.8354, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(153.0538, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\1458973107.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer.set_params(t_min__, t_max__, max_vect__[:512], in_scalar=scalar__)\n",
    "print(t_min, t_max, scalar___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "tensor(0.0002, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - F.hardtanh(out_x)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_all_all(nn.Module):\n",
    "    \"\"\"\n",
    "    from all to all (pure linear layer)\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W1 = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        W2 = torch.concatenate((-weights.T, weights.T),dim=1)\n",
    "        W = torch.concatenate((W1,W2),dim=0)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((2*input_units,), W, b1)\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, in_scalar=1):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val, in_scalar = self.first.set_params(t_min_prev, t_min,in_ranges_max, in_scalar=in_scalar)\n",
    "        return tmin1, tmax1, first_val, in_scalar\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sh = list(input_ttfs.shape)\n",
    "sh[1] = sh[1]\n",
    "binary_mask = torch.randint(0,2,sh)\n",
    "binary_mask = torch.concat((binary_mask, 1-binary_mask),dim=1)\n",
    "sh[1] = sh[1]*2\n",
    "\n",
    "input_ttfs = (torch.rand(sh)*(tmax - tmin) + tmin) * binary_mask\n",
    "input_x = ((tmax - input_ttfs[0,:512]) - (tmax - input_ttfs[0,512:]))*scalar__\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "max_vect__ = torch.rand(1024)\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)\n",
    "print(input_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = SpikingDense_all_all(10,512, '',model2.fc.weight, model2.fc.bias,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_14000\\3582702955.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp, scalar___ = layer2.set_params(t_min__, t_max__, max_vect__, scalar__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor(0.0023, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer2.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print((((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:])*scalar___ - out_x).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8288, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
