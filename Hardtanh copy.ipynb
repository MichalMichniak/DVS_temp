{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, end_maxpool = False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        if self.end_maxpool:\n",
    "            out = F.relu(out, inplace=False)\n",
    "        else:\n",
    "            out = F.hardtanh(out, inplace=False, min_val=-1.0, max_val=1.0)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2, end_maxpool = True)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, end_maxpool = False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                layers.append(block(self.inplanes, planes, end_maxpool = True))\n",
    "            else:\n",
    "                layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "      )\n",
       "      (relu): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_Hardtanh_ReLUmaxpool.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na ISNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1],torch.zeros(self.kernel[:-1].shape)), self.kernel[-1].unsqueeze(0)))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1],torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.kernel[-1].unsqueeze(0), torch.zeros(self.kernel[-1].unsqueeze(0).shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        # print(max_W.shape)\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        # print(max_input.shape)\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1))\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1), torch.zeros(self.B.squeeze(1).shape))))\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), max_values\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # WyciÄ…ganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W,self.B.T),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0):\n",
    "        output_val = input1_val + input2_val\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj1 + tj2 - 2*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0):\n",
    "        self.input1_val = input1_val\n",
    "        output_val = input1_val\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        ### Check ###\n",
    "        if((tj2>self.t_min).any() or (tj1>self.t_min).any()):\n",
    "            print(\"XDDD1\")\n",
    "        print(tj1.shape)\n",
    "        if(len(tj1.shape) == 3):\n",
    "            if((torch.amax(self.t_min - tj1, dim=(1, 2))>self.input1_val).any()):\n",
    "                print(\"XDDD2\")\n",
    "                print(f\"XDDD2 {(torch.amax(self.t_min - tj1, dim=(1, 2))-self.input1_val).abs().max()}\")\n",
    "        else:\n",
    "            if((torch.amax(self.t_min - tj1, dim=(2, 3))>self.input1_val).any()):\n",
    "                print(\"XDDD2\")\n",
    "                print(f\"XDDD2 {(torch.amax(self.t_min - tj1, dim=(2, 3))-self.input1_val).abs().max()}\")\n",
    "        tj1_temp = (tj2-tj1)*(tj1<tj2)\n",
    "        tj2_temp = (tj1-tj2)*(tj1>=tj2)\n",
    "\n",
    "        V = tj1_temp - tj2_temp\n",
    "        \n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "            print(f\"{((tj1 - self.t_min) - (tj2 - self.t_min)).max()}\")\n",
    "\n",
    "        V = (tj1 - self.t_min) - (tj2 - self.t_min)\n",
    "        if((V>threshold).any()):\n",
    "            print(f\"ERROR SubSNNLayer1 V {V.max()}, thr {threshold}\")\n",
    "        \n",
    "        ### END Check ###\n",
    "        ti = tj1 - self.t_min - (tj2 - self.t_min)  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "\n",
    "        max_input = max(in_ranges_max)\n",
    "        max_V = max_input\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), in_ranges_max\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj - self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max = self.layers[i].set_params(tmin, tmax,in_ranges_max)\n",
    "        return tmin, tmax, in_ranges_max\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_resblock0 = model2.layer0[0](model_maxpool)\n",
    "model_resblock1 = model2.layer0[1](model_resblock0)\n",
    "model_resblock2 = model2.layer0[2](model_resblock1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_Htanh(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_Htanh, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        \n",
    "        kernels_neg = torch.concat((-kernels,kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_neg = -biases\n",
    "        else:\n",
    "            biases_neg = None\n",
    "\n",
    "        kernels_new = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new = torch.concat((biases_pos, biases_neg))\n",
    "        print(biases_new.shape)\n",
    "        self.conv_first = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "        \n",
    "        kernels_new2 = torch.concat((kernels_pos, kernels_neg), dim=0)\n",
    "        biases_new2 = torch.concat((biases_pos, biases_neg)) - 1\n",
    "        self.conv_second = SpikingConv2D(2*filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new2, biases=biases_new2)\n",
    "        self.sub = SubSNNLayer()\n",
    "        self.filters = filters*2\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        if(in_ranges_max.shape[0] != self.filters):\n",
    "            in_ranges_max = torch.concat((in_ranges_max,torch.zeros(in_ranges_max.shape)))\n",
    "        tmin1, tmax1, first_val = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, minimal_t_max-1)\n",
    "        tmin2, tmax2, second_val = self.conv_second.set_params(t_min_prev, t_min, in_ranges_max, tmax1)\n",
    "\n",
    "        tmin1, tmax1, first_val = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max, tmax2)\n",
    "        self.t_max = tmax1\n",
    "        tmins, tmaxs, sub_val = self.sub.set_params(t_min, tmax1, first_val,second_val)\n",
    "        tmaxs = tmins+1\n",
    "        self.sub.t_max = tmaxs\n",
    "        self.t_max = tmaxs\n",
    "        # Returning for function signature consistency\n",
    "        return tmins, self.t_max, torch.minimum(sub_val, torch.ones(sub_val.shape))\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        tj2 = self.conv_second(tj)\n",
    "        tj_sub = self.sub(tj1, tj2)\n",
    "\n",
    "        return tj_sub\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_all(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, bias=0):\n",
    "        super(AddSNNLayer_all, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.B = bias # bias for all inputs (for Hard tanh)\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0):\n",
    "        if input2_val.shape[0] != input1_val.shape[0]:\n",
    "            input2_val = torch.concat((input2_val, torch.zeros(input2_val.shape)))\n",
    "        output_val = input1_val + input2_val + self.B\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "\n",
    "        self.channels = tj1.shape[1]//2\n",
    "\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = torch.concat((tj1[0, :self.channels] + tj2[0, :self.channels] - tj1[0, self.channels:] - tj2[0, self.channels:], \n",
    "                           tj1[0, self.channels:] + tj2[0, self.channels:] - tj1[0, :self.channels] - tj2[0, :self.channels])) + self.B*(1) + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer_Htanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer_Htanh, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        self.first = AddSNNLayer_all()\n",
    "        self.second = AddSNNLayer_all(1)\n",
    "        self.sub = SubSNNLayer()\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0):\n",
    "        tmin1, tmax1, first_val = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=t_min+1)\n",
    "        tmin2, tmax2, second_val = self.second.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax1)\n",
    "\n",
    "        tmin1, tmax1, first_val = self.first.set_params(t_min_prev, t_min,input1_val, input2_val, minimal_t_max=tmax2)\n",
    "\n",
    "        tmins, tmaxs, sub_val = self.sub.set_params(t_min, tmax1, first_val,second_val) ## t_min as angument do nothing\n",
    "        self.sub.t_max = tmaxs\n",
    "        return tmins, tmaxs, torch.minimum(sub_val,torch.ones(sub_val.shape))\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        tj_first = self.first(tj1, tj2)\n",
    "        tj_second = self.second(tj1, tj2)\n",
    "        tj_sub = self.sub(tj_first, tj_second)\n",
    "        return tj_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D_all(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D_all, self).__init__()\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        kernels_pos = torch.concat((kernels,-kernels), dim=1 )\n",
    "        if biases is not None:\n",
    "            biases_pos = biases\n",
    "        else:\n",
    "            biases_pos = None\n",
    "        kernels_new = kernels_pos\n",
    "        biases_new = biases_pos\n",
    "        self.conv_first = SpikingConv2D(filters, name, device = device, padding=padding, stride=stride, kernel_size=kernel_size,robustness_params=robustness_params, kernels=kernels_new, biases=biases_new)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val = self.conv_first.set_params(t_min_prev, t_min, in_ranges_max)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return tmin1, tmax1, first_val\n",
    "        # return tmin1, self.t_max, torch.minimum(first_val, torch.ones(first_val.shape))\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        tj1 = self.conv_first(tj)\n",
    "        return tj1\n",
    "        # return tj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock_all(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\", end_maxpool = False):\n",
    "        super(ResidualSNNBlock_all, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        if (downsample is not None):\n",
    "            self.conv1 = SpikingConv2D_all(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        else:\n",
    "            self.conv1 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D_Htanh(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        if end_maxpool:\n",
    "            self.add_layer = AddSNNLayer_all()\n",
    "        else:\n",
    "            self.add_layer = AddSNNLayer_Htanh()\n",
    "        self.out_channels = out_channels\n",
    "        self.end_maxpool = end_maxpool\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "        self.t_max1 = t_max1\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "            self.t_max1_dummy = t_max1_dummy\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "            residual = torch.concat((residual,torch.ones(residual.shape)*self.t_max1_dummy), dim=1)\n",
    "            out = torch.concat((out,torch.ones(out.shape)*self.t_max1), dim=1)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual) # no need for adding negative part\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN_all(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0', end_maxpool = False):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D_all(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock_all(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            if i == blocks-1 and end_maxpool:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device, end_maxpool = True))\n",
    "            else:\n",
    "                self.layers.append(ResidualSNNBlock_all(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max = self.layers[i].set_params(tmin, tmax,in_ranges_max)\n",
    "        return tmin, tmax, in_ranges_max\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            print(i)\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(4.5586, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "max_vect = torch.tensor([1,1,1,1,1])\n",
    "tmin, tmax, max_vect = conv_first.set_params(0,1,max_vect)\n",
    "print(tmin, tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "print(model_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2543e-04, 0.0000e+00, 6.4826e-02, 2.8124e-02, 0.0000e+00, 1.0669e+00,\n",
      "        3.5316e-07, 0.0000e+00, 1.8713e-03, 0.0000e+00, 1.5711e-05, 5.7183e-05,\n",
      "        1.7728e-06, 1.9651e-05, 0.0000e+00, 1.4251e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.4909e-02, 0.0000e+00, 3.2300e-02, 1.6224e+00,\n",
      "        0.0000e+00, 3.6996e-02, 5.6862e-02, 1.2020e-06, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 5.0145e-06, 0.0000e+00, 8.9199e-03, 0.0000e+00,\n",
      "        1.5293e-02, 0.0000e+00, 4.6955e-02, 0.0000e+00, 5.3887e-03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2771e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.5586e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5823e-05, 3.8386e-03, 5.4359e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.7028e-03, 1.4734e+00],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tworzenie przykÅ‚adowego array'a\n",
    "values = max_vect.detach().numpy()\n",
    "labels = [ i for i in range(len(max_vect))]\n",
    "\n",
    "# Tworzenie wykresu sÅ‚upkowego\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "\n",
    "# Dodanie etykiet\n",
    "plt.ylabel('$x_{max}$')\n",
    "plt.xlabel('Channel number')\n",
    "plt.title('maksymalne wartoÅ›ci kaÅ¼dego kanaÅ‚u')\n",
    "\n",
    "# WyÅ›wietlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 224, 224])\n",
      "tensor(1.1027e-06, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "\n",
    "# SNN_input = torch.concat((SNN_input, torch.ones(SNN_input.shape)),dim=1)\n",
    "print(SNN_input.shape)\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "# print(out1)\n",
    "out1_x = model2.conv1(random_input)\n",
    "temp = (conv_first.t_max - out1)\n",
    "# print((temp[0,:64] - temp[0,64:] - model_conv1).abs().max())\n",
    "print((temp - model_conv1).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2543e-04, 0.0000e+00, 6.4826e-02, 2.8124e-02, 0.0000e+00, 1.0669e+00,\n",
      "        3.5316e-07, 0.0000e+00, 1.8713e-03, 0.0000e+00, 1.5711e-05, 5.7183e-05,\n",
      "        1.7728e-06, 1.9651e-05, 0.0000e+00, 1.4251e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.4909e-02, 0.0000e+00, 3.2300e-02, 1.6224e+00,\n",
      "        0.0000e+00, 3.6996e-02, 5.6862e-02, 1.2020e-06, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 5.0145e-06, 0.0000e+00, 8.9199e-03, 0.0000e+00,\n",
      "        1.5293e-02, 0.0000e+00, 4.6955e-02, 0.0000e+00, 5.3887e-03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2771e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.5586e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5823e-05, 3.8386e-03, 5.4359e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.7028e-03, 1.4734e+00],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.amax(tmax -out1, dim=(2, 3))<=max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1076e-04, 0.0000e+00, 3.0877e-02, 1.8810e-02, 0.0000e+00, 4.5661e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3351e-05, 2.4319e-05,\n",
      "         1.9073e-06, 1.7166e-05, 0.0000e+00, 7.3156e-03, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.2425e-04, 0.0000e+00, 1.4609e-02, 4.1380e-01,\n",
      "         0.0000e+00, 1.3092e-02, 1.0612e-02, 9.5367e-07, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.8610e-06, 0.0000e+00, 6.9151e-03, 0.0000e+00,\n",
      "         9.1343e-03, 0.0000e+00, 1.0820e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4134e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0700e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6294e-06, 2.7514e-03, 3.2574e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8673e-01]],\n",
      "       grad_fn=<AmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.amax(tmax -out1, dim=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0431e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "\n",
    "print(((tmax - out2) - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [],
   "source": [
    "addsnn2 = AddSNNLayer_all(1)\n",
    "addsnn1 = AddSNNLayer_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(2.3842e-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "SNN_input1 = 1 - random_input +1\n",
    "SNN_input2 = 1 - random_input +1\n",
    "\n",
    "val_in1, val_in2 = torch.concat((torch.ones(5), torch.zeros(5))),torch.concat((torch.ones(5), torch.zeros(5)))\n",
    "tmin1, tmax1, val1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2)\n",
    "tmin2, tmax2, val2 = addsnn2.set_params(0+1,1+1,val_in1,val_in2,tmax1)\n",
    "tmin1, tmax1, val1 = addsnn1.set_params(0+1,1+1,val_in1,val_in2,tmax2)\n",
    "\n",
    "outadd1 = addsnn1(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd1.shape)\n",
    "print(((tmax1 - outadd1)[:5] - (tmax1 - outadd1)[5:] - F.relu(random_input*2)).abs().max())# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(2.3842e-07)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "outadd2 = addsnn2(torch.concat((SNN_input1, torch.ones(SNN_input1.shape)+1),dim=1),torch.concat((SNN_input2, torch.ones(SNN_input2.shape)+1),dim=1))\n",
    "print(outadd2.shape)\n",
    "print(((tmax1 - outadd2)[:5] - (tmax1 - outadd2)[5:] - F.relu(random_input*2-1)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.amax(tmax1 - outadd1, dim=(1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = SubSNNLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n"
     ]
    }
   ],
   "source": [
    "tmins, tmaxs, sub_val = sub.set_params(0, tmax1, val1,val2)\n",
    "# sub.t_max = tmins+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 224, 224])\n",
      "tensor(1.1921e-06)\n"
     ]
    }
   ],
   "source": [
    "outsub = sub(outadd1,outadd2)\n",
    "print(((sub.t_max-outsub)[:5] - (sub.t_max-outsub)[5:] - F.hardtanh(random_input*2)).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resblock test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "resblocksnn = ResidualSNNBlock_all(model2.layer0[0],64,64, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.8919, grad_fn=<AddBackward0>) tensor(30.5207, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmin2, tmax2, max_vect2 = resblocksnn.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))))\n",
    "print(tmin2, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 4.112094879150391\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.2628345489501953\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 2.496396541595459\n"
     ]
    }
   ],
   "source": [
    "print(torch.concat((out2, torch.ones(out2.shape) * tmin),dim=1).shape)\n",
    "out3res = resblocksnn(torch.concat((out2, torch.ones(out2.shape) * tmax),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<MaxBackward1>)\n",
      "tensor(3.3155e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out3res)[:64].max())\n",
    "print(((tmax2 - out3res)[:64] - (tmax2 - out3res)[64:]  - model_resblock0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5586, grad_fn=<AddBackward0>) tensor(30.5207, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tmax, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "tensor(34.6481, grad_fn=<AddBackward0>) tensor(45.7118, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "resblocksnn2 = ResidualSNNBlock_all(model2.layer0[1],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2 = resblocksnn2.set_params(tmin2, tmax2, max_vect2)\n",
    "print(tmin2, tmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.898519076348748e-05\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 9.504146873950958e-07\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.0\n"
     ]
    }
   ],
   "source": [
    "out4res = resblocksnn2(out3res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<MaxBackward1>)\n",
      "tensor(9.7917e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out4res)[:64].max())\n",
    "print(((tmax2 - out4res)[:64] - (tmax2 - out4res)[64:]  - model_resblock1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "tensor(50.0252, grad_fn=<AddBackward0>) tensor(61.1081, grad_fn=<AddBackward0>)\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 0.1372537761926651\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 0.06854858994483948\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.0\n"
     ]
    }
   ],
   "source": [
    "resblocksnn3 = ResidualSNNBlock_all(model2.layer0[2],64,64, device='cpu')\n",
    "tmin2, tmax2, max_vect2 = resblocksnn3.set_params(tmin2, tmax2, max_vect2)\n",
    "print(tmin2, tmax2)\n",
    "out5res = resblocksnn3(out4res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<MaxBackward1>)\n",
      "tensor(1.4869e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax2 - out5res)[:64].max())\n",
    "print(((tmax2 - out5res)[:64] - (tmax2 - out5res)[64:]  - model_resblock2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = None\n",
    "\n",
    "# resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy, device='cpu')\n",
    "# tmin, tmax, max_vect = resblockSNN.set_params(0,1, max_vect)\n",
    "# print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.0252, grad_fn=<AddBackward0>) tensor(61.1081, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN_all(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmax_prev = tmax\n",
    "tmin, tmax, max_vect = layer0SNN.set_params(tmin, tmax, torch.concat((max_vect, torch.zeros(max_vect.shape))))\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 4.112094879150391\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.2628345489501953\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 2.496396541595459\n",
      "1\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.898519076348748e-05\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 9.504146873950958e-07\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.0\n",
      "2\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 0.1372537761926651\n",
      "torch.Size([1, 128, 56, 56])\n",
      "torch.Size([1, 128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 0.06854858994483948\n",
      "torch.Size([128, 56, 56])\n",
      "XDDD2\n",
      "XDDD2 1.0\n",
      "torch.Size([128, 56, 56])\n",
      "tensor(1.4869e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(torch.concat((out2, torch.ones(out2.shape) * tmax_prev),dim=1))\n",
    "print(out_3.shape)\n",
    "print(((tmax - out_3)[:64] - (tmax - out_3)[64:] - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "tensor(124.6347, grad_fn=<AddBackward0>) tensor(135.6811, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN_all(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer1SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 7.564406394958496\n",
      "torch.Size([256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 3.1122567653656006\n",
      "1\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 3.815926902461797e-05\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 3.8067519199103117e-06\n",
      "torch.Size([256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 1.0\n",
      "2\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 4.337039717938751e-05\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 3.8067519199103117e-06\n",
      "torch.Size([256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 1.0\n",
      "3\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 5.83412911510095e-05\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 3.80667916033417e-06\n",
      "torch.Size([256, 28, 28])\n",
      "XDDD2\n",
      "XDDD2 1.0\n",
      "torch.Size([256, 28, 28])\n",
      "tensor(4.1082e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "print((tmax - out_4).shape)\n",
    "print(((tmax - out_4)[ :128] - (tmax - out_4)[ 128:] - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(241.2561, grad_fn=<AddBackward0>) tensor(252.4983, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN_all(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer2SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 3.9207000732421875\n",
      "1\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.2245824635028839\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.206146240234375\n",
      "torch.Size([512, 14, 14])\n",
      "2\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.2408289611339569\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.22091877460479736\n",
      "torch.Size([512, 14, 14])\n",
      "3\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.21738310158252716\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.2228900045156479\n",
      "torch.Size([512, 14, 14])\n",
      "4\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.19780422747135162\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.317875474691391\n",
      "torch.Size([512, 14, 14])\n",
      "5\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.2697872519493103\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "XDDD2\n",
      "XDDD2 0.31610745191574097\n",
      "torch.Size([512, 14, 14])\n",
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print(((tmax - out_5)[:256] - (tmax - out_5)[256:] - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\1310482246.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3502596109.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(355.6348, grad_fn=<AddBackward0>) tensor(357.6348, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN_all(model2.layer3, 256, 512, 3,device = 'cpu',end_maxpool=True)\n",
    "tmin, tmax, max_vect = layer3SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 29.74102020263672\n",
      "torch.Size([1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 3.2786622047424316\n",
      "1\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 1.0495229959487915\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 2.4805102348327637\n",
      "torch.Size([1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 2.0\n",
      "2\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 16.065122604370117\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "XDDD2\n",
      "XDDD2 7.90975284576416\n",
      "tensor(0.0002, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print(((tmax - out_6)[:512] - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6[:512])\n",
    "\n",
    "print(((tmax - out7) - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(357.6348, grad_fn=<AddBackward0>) tensor(372.0959, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T\n",
    "biases = model2.fc.bias\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin_, tmax_, max_vect_ = spiking_dense.set_params(tmin, tmax, max_vect[:512])\n",
    "print(tmin_, tmax_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor(7.7575e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "\n",
    "print((tmax_ - out8 - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(8.9117, grad_fn=<AddBackward0>), tensor(9.9117, grad_fn=<AddBackward0>), 'c'), (tensor(11.2631, grad_fn=<AddBackward0>), tensor(12.2631, grad_fn=<AddBackward0>), 'c'), (tensor(16.8919, grad_fn=<AddBackward0>), tensor(30.5207, grad_fn=<AddBackward0>), 'a'), (tensor(30.5208, grad_fn=<AddBackward0>), tensor(31.5208, grad_fn=<AddBackward0>), 'c'), (tensor(31.5845, grad_fn=<AddBackward0>), tensor(32.5845, grad_fn=<AddBackward0>), 'c'), (tensor(34.6481, grad_fn=<AddBackward0>), tensor(45.7118, grad_fn=<AddBackward0>), 'a'), (tensor(45.8563, grad_fn=<AddBackward0>), tensor(46.8563, grad_fn=<AddBackward0>), 'c'), (tensor(46.9423, grad_fn=<AddBackward0>), tensor(47.9423, grad_fn=<AddBackward0>), 'c'), (tensor(50.0252, grad_fn=<AddBackward0>), tensor(61.1081, grad_fn=<AddBackward0>), 'a'), (tensor(61.1081, grad_fn=<AddBackward0>), tensor(63.9411, grad_fn=<AddBackward0>), 'c'), (tensor(71.7274, grad_fn=<AddBackward0>), tensor(72.7274, grad_fn=<AddBackward0>), 'c'), (tensor(76.9956, grad_fn=<AddBackward0>), tensor(90.2639, grad_fn=<AddBackward0>), 'a'), (tensor(90.2640, grad_fn=<AddBackward0>), tensor(91.2640, grad_fn=<AddBackward0>), 'c'), (tensor(91.3103, grad_fn=<AddBackward0>), tensor(92.3103, grad_fn=<AddBackward0>), 'c'), (tensor(94.3566, grad_fn=<AddBackward0>), tensor(105.4029, grad_fn=<AddBackward0>), 'a'), (tensor(105.4030, grad_fn=<AddBackward0>), tensor(106.4030, grad_fn=<AddBackward0>), 'c'), (tensor(106.4493, grad_fn=<AddBackward0>), tensor(107.4493, grad_fn=<AddBackward0>), 'c'), (tensor(109.4956, grad_fn=<AddBackward0>), tensor(120.5419, grad_fn=<AddBackward0>), 'a'), (tensor(120.5420, grad_fn=<AddBackward0>), tensor(121.5420, grad_fn=<AddBackward0>), 'c'), (tensor(121.5884, grad_fn=<AddBackward0>), tensor(122.5884, grad_fn=<AddBackward0>), 'c'), (tensor(124.6347, grad_fn=<AddBackward0>), tensor(135.6811, grad_fn=<AddBackward0>), 'a'), (tensor(135.6811, grad_fn=<AddBackward0>), tensor(141.2348, grad_fn=<AddBackward0>), 'c'), (tensor(152.5302, grad_fn=<AddBackward0>), tensor(153.5302, grad_fn=<AddBackward0>), 'c'), (tensor(158.6710, grad_fn=<AddBackward0>), tensor(172.8119, grad_fn=<AddBackward0>), 'a'), (tensor(173.0471, grad_fn=<AddBackward0>), tensor(174.0471, grad_fn=<AddBackward0>), 'c'), (tensor(174.2617, grad_fn=<AddBackward0>), tensor(175.2617, grad_fn=<AddBackward0>), 'c'), (tensor(177.4762, grad_fn=<AddBackward0>), tensor(188.6908, grad_fn=<AddBackward0>), 'a'), (tensor(188.9446, grad_fn=<AddBackward0>), tensor(189.9446, grad_fn=<AddBackward0>), 'c'), (tensor(190.1930, grad_fn=<AddBackward0>), tensor(191.1930, grad_fn=<AddBackward0>), 'c'), (tensor(193.4414, grad_fn=<AddBackward0>), tensor(204.6898, grad_fn=<AddBackward0>), 'a'), (tensor(204.9207, grad_fn=<AddBackward0>), tensor(205.9207, grad_fn=<AddBackward0>), 'c'), (tensor(206.1677, grad_fn=<AddBackward0>), tensor(207.1677, grad_fn=<AddBackward0>), 'c'), (tensor(209.2934, grad_fn=<AddBackward0>), tensor(220.4191, grad_fn=<AddBackward0>), 'a'), (tensor(220.6241, grad_fn=<AddBackward0>), tensor(221.6241, grad_fn=<AddBackward0>), 'c'), (tensor(221.9529, grad_fn=<AddBackward0>), tensor(222.9529, grad_fn=<AddBackward0>), 'c'), (tensor(225.1715, grad_fn=<AddBackward0>), tensor(236.3901, grad_fn=<AddBackward0>), 'a'), (tensor(236.6608, grad_fn=<AddBackward0>), tensor(237.6608, grad_fn=<AddBackward0>), 'c'), (tensor(238.0139, grad_fn=<AddBackward0>), tensor(239.0139, grad_fn=<AddBackward0>), 'c'), (tensor(241.2561, grad_fn=<AddBackward0>), tensor(252.4983, grad_fn=<AddBackward0>), 'a'), (tensor(252.4983, grad_fn=<AddBackward0>), tensor(259.7513, grad_fn=<AddBackward0>), 'c'), (tensor(289.6793, grad_fn=<AddBackward0>), tensor(290.6793, grad_fn=<AddBackward0>), 'c'), (tensor(295.0820, grad_fn=<AddBackward0>), tensor(308.4847, grad_fn=<AddBackward0>), 'a'), (tensor(309.5437, grad_fn=<AddBackward0>), tensor(310.5437, grad_fn=<AddBackward0>), 'c'), (tensor(313.0313, grad_fn=<AddBackward0>), tensor(314.0313, grad_fn=<AddBackward0>), 'c'), (tensor(317.0313, grad_fn=<AddBackward0>), tensor(329.0313, grad_fn=<AddBackward0>), 'a'), (tensor(345.4436, grad_fn=<AddBackward0>), tensor(346.4436, grad_fn=<AddBackward0>), 'c'), (tensor(354.6348, grad_fn=<AddBackward0>), tensor(355.6348, grad_fn=<AddBackward0>), 'c'), (tensor(355.6348, grad_fn=<AddBackward0>), tensor(357.6348, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'czas')"
      ]
     },
     "execution_count": 1560,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(tt)\n",
    "plt.xlabel(\"Nr. warstwy\")\n",
    "plt.ylabel(\"czas\")\n",
    "# plt.ylim([0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [(tt[i])/(tt[i-1]) for i in range(2,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b50c9b8310>]"
      ]
     },
     "execution_count": 1562,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOP0lEQVR4nO3deXwU5f0H8M/sbnYTcmwIkDtAEBAkEsKlEUEElCKloi1iteJdj6Ai6s+iFrXaxnpVrYhnoR6IoAYqKIpguOQMBAhIuAIJuQhHdnNu9pjfH7sz2YRks/eA+bxfr23JZiYzYSX7yfN8n+8jiKIogoiIiEghKqVvgIiIiDo3hhEiIiJSFMMIERERKYphhIiIiBTFMEJERESKYhghIiIiRTGMEBERkaIYRoiIiEhRGqVvwB02mw1lZWWIjIyEIAhK3w4RERG5QRRF1NTUIDExESpV++MfF0QYKSsrQ0pKitK3QURERF4oKSlBcnJyu5+/IMJIZGQkAPs3ExUVpfDdEBERkTuMRiNSUlLk9/H2XBBhRJqaiYqKYhghIiK6wHRUYsECViIiIlIUwwgREREpimGEiIiIFMUwQkRERIpiGCEiIiJFMYwQERGRohhGiIiISFEMI0RERKQohhEiIiJSFMMIERERKYphhIiIiBTFMEJERESKuiA2yguUr/JOYG+pAZPS4nFZn25K3w4REVGn1KlHRnIPVmHhz8ewr8yo9K0QERF1Wp06jOg09m/fZLEpfCdERESdF8MIAJPFqvCdEBERdV6dPIyoAQBNHBkhIiJSTOcOIyGcpiEiIlJapw4jWjWnaYiIiJTWqcOIPDJi5sgIERGRUjp3GHHUjHCahoiISDmdPIzYv30WsBIRESmnU4cRLZf2EhERKa5ThxE2PSMiIlJeJw8jrBkhIiJSWucOIyGsGSEiIlJa5w4jrBkhIiJSHMMIOE1DRESkpE4eRhw1I2x6RkREpBiPwkh2djZGjBiByMhIxMbGYurUqSgsLHT7/MWLF0MQBEydOtXT+wwITtMQEREpz6Mwsm7dOmRlZWHLli1YvXo1zGYzrr32WtTV1XV47rFjx/D4449j9OjRXt+sv3HXXiIiIuVpPDl41apVLT5euHAhYmNjkZeXhzFjxrR7ntVqxa233ornn38eGzZsQHV1tVc3629a1owQEREpzqeaEYPBAACIiYlxedzf/vY3xMbG4u677/blcn4nTdNYbCIsVgYSIiIiJXg0MuLMZrNh1qxZGDVqFNLS0to9buPGjfjoo4+Qn5/v9tc2mUwwmUzyx0aj0dvbdEnqMwIATVYbNOpOXc9LRESkCK/ffbOyslBQUIDFixe3e0xNTQ1uu+02fPDBB+jevbvbXzs7Oxt6vV5+pKSkeHubLmmdwgfrRoiIiJQhiKIoenrSzJkzsXz5cqxfvx6pqantHpefn4+MjAyo1Wr5OZvN/qavUqlQWFiIiy666Jzz2hoZSUlJgcFgQFRUlKe361Lfp76FxSZi61PjERcV6tevTURE1JkZjUbo9foO3789mqYRRREPPfQQcnJykJub6zKIAMCAAQOwd+/eFs8988wzqKmpwZtvvtnuiIdOp4NOp/Pk1rym1ahgabKy1wgREZFCPAojWVlZWLRoEZYvX47IyEhUVFQAAPR6PcLCwgAAM2bMQFJSErKzsxEaGnpOPUl0dDQAuKwzCSadRoX6Jit7jRARESnEozAyf/58AMDYsWNbPL9gwQLccccdAIDi4mKoVBdOIai914iZy3uJiIgU4vE0TUdyc3Ndfn7hwoWeXDLgpBU1DCNERETKuHCGMAJEWlHDaRoiIiJldPowwpERIiIiZTGMcOdeIiIiRTGMOFrCN7EdPBERkSIYRqTN8sysGSEiIlJCpw8j3LmXiIhIWZ0+jMg1IwwjREREimAY0XBpLxERkZIYRhxLe7lrLxERkTI6fRjRqjlNQ0REpKROH0bkpmfsM0JERKQIhhHWjBARESmKYcSxmoY1I0RERMro9GGEfUaIiIiU1enDCKdpiIiIlMUwwpERIiIiRTGMhHDXXiIiIiUxjHDXXiIiIkV1+jCiZc0IERGRojp9GJFrRjhNQ0REpAiGEe7aS0REpCiGEQ03yiMiIlISwwhrRoiIiBTFMMJpGiIiIkUxjISw6RkREZGSGEYc0zRWmwgLe40QEREFHcOIY5oGYOMzIiIiJXT6MCI1PQPYa4SIiEgJnT6MqFUCNCoBAOtGiIiIlNDpwwjA5b1ERERKYhhB8869bHxGREQUfAwjALRqLu8lIiJSCsMInHuNcJqGiIgo2BhGwJ17iYiIlMQwAraEJyIiUpJHYSQ7OxsjRoxAZGQkYmNjMXXqVBQWFro854MPPsDo0aPRtWtXdO3aFRMmTMC2bdt8uml/a15NwzBCREQUbB6FkXXr1iErKwtbtmzB6tWrYTabce2116Kurq7dc3Jzc/HHP/4RP/30EzZv3oyUlBRce+21KC0t9fnm/UXLpb1ERESK0Xhy8KpVq1p8vHDhQsTGxiIvLw9jxoxp85zPPvusxccffvghvvrqK6xZswYzZszw8HYDgyMjREREyvEojLRmMBgAADExMW6fU19fD7PZ7PIck8kEk8kkf2w0Gr2/STewZoSIiEg5Xhew2mw2zJo1C6NGjUJaWprb5z355JNITEzEhAkT2j0mOzsber1efqSkpHh7m26Rlvay6RkREVHweR1GsrKyUFBQgMWLF7t9zksvvYTFixcjJycHoaGh7R43Z84cGAwG+VFSUuLtbbqluekZa0aIiIiCzatpmpkzZ2LFihVYv349kpOT3Trn1VdfxUsvvYQff/wRgwcPdnmsTqeDTqfz5ta8Ijc9Y58RIiKioPMojIiiiIceegg5OTnIzc1FamqqW+e9/PLL+Pvf/47vv/8ew4cP9+pGA4k1I0RERMrxKIxkZWVh0aJFWL58OSIjI1FRUQEA0Ov1CAsLAwDMmDEDSUlJyM7OBgD885//xNy5c7Fo0SL07t1bPiciIgIRERH+/F68xl17iYiIlONRzcj8+fNhMBgwduxYJCQkyI8vvvhCPqa4uBjl5eUtzmlqasIf/vCHFue8+uqr/vsufCSNjLCAlYiIKPg8nqbpSG5ubouPjx075sklFKFlnxEiIiLFcG8asOkZERGRkhhG4LyahjUjREREwcYwAqeaEStHRoiIiIKNYQRONSPsM0JERBR0DCPg0l4iIiIlMYyABaxERERKYhgBO7ASEREpiWEE3LWXiIhISQwj4K69RERESmIYARAawpoRIiIipTCMwKlmhEt7iYiIgo5hBM2radj0jIiIKPgYRtDc9MxqE2FhICEiIgoqhhE0T9MArBshIiIKNoYRNI+MAAwjREREwcYwAkCtEhCiFgBweS8REVGwMYw4yDv3cmSEiIgoqBhGHLTcn4aIiEgRDCMO8mZ57DVCREQUVAwjDs0797JmhIiIKJgYRhxYM0JERKQMhhEH1owQEREpg2HEgdM0REREymAYcdBx514iIiJFMIw4cOdeIiIiZTCMOMjTNNwoj4iIKKgYRhzkAlYza0aIiIiCiWHEQcfVNERERIpgGHGQa0YYRoiIiIKKYcRBGhlh0zMiIqLgYhhx0LLPCBERkSIYRhw4TUNERKQMhhEHuekZ+4wQEREFFcOIA9vBExERKcOjMJKdnY0RI0YgMjISsbGxmDp1KgoLCzs8b+nSpRgwYABCQ0Nx6aWX4ttvv/X6hgOFu/YSEREpw6Mwsm7dOmRlZWHLli1YvXo1zGYzrr32WtTV1bV7zs8//4w//vGPuPvuu7Fr1y5MnToVU6dORUFBgc8370/ctZeIiEgZgiiKorcnV1VVITY2FuvWrcOYMWPaPGb69Omoq6vDihUr5Ocuv/xyDBkyBO+++65b1zEajdDr9TAYDIiKivL2dl36ZncZHvp8Fy7vE4PFf84MyDWIiIg6E3ffv32qGTEYDACAmJiYdo/ZvHkzJkyY0OK5iRMnYvPmze2eYzKZYDQaWzwCjR1YiYiIlOF1GLHZbJg1axZGjRqFtLS0do+rqKhAXFxci+fi4uJQUVHR7jnZ2dnQ6/XyIyUlxdvbdJsuhDUjRERESvA6jGRlZaGgoACLFy/25/0AAObMmQODwSA/SkpK/H6N1rRqjowQEREpQePNSTNnzsSKFSuwfv16JCcnuzw2Pj4elZWVLZ6rrKxEfHx8u+fodDrodDpvbs1rcp8RLu0lIiIKKo9GRkRRxMyZM5GTk4O1a9ciNTW1w3MyMzOxZs2aFs+tXr0amZnnV5GoXDPCpmdERERB5dHISFZWFhYtWoTly5cjMjJSrvvQ6/UICwsDAMyYMQNJSUnIzs4GADzyyCO46qqr8Nprr2Hy5MlYvHgxduzYgffff9/P34pv2A6eiIhIGR6NjMyfPx8GgwFjx45FQkKC/Pjiiy/kY4qLi1FeXi5/fMUVV2DRokV4//33kZ6eji+//BLLli1zWfSqBO7aS0REpAyPRkbcaUmSm5t7znPTpk3DtGnTPLlU0Dm3gxdFEYIgKHxHREREnQP3pnGQpmlsImCxed0HjoiIiDzEMOIgraYBWDdCREQUTAwjDlKfEYB1I0RERMHEMOKgUgkIUdvrRNhrhIiIKHgYRpzIy3vZa4SIiChoGEaccLM8IiKi4GMYceK8vJeIiIiCg2HECXfuJSIiCj6GESfcuZeIiCj4GEaccOdeIiKi4GMYccKde4mIiIKPYcSJtLS3ycowQkREFCwMI060HBkhIiIKOoYRJ1zaS0REFHwMI07Y9IyIiCj4GEacyO3gGUaIiIiChmHESfPSXoYRIiKiYGEYcdLc9Iw1I0RERMHCMOJEHhnhahoiIqKgYRhxwpoRIiKi4GMYcSKtpuFGeURERMHDMOJEyz4jREREQccw4oTTNERERMHHMOKETc+IiIiCj2HEibSaponTNEREREHDMOKE0zRERETBxzDihLv2EhERBR/DiBPu2ktERBR8DCNOWMBKREQUfAwjTqSaETY9IyIiCh6GESdajowQEREFHcOIE9aMEBERBR/DiBN5116LDaIoKnw3REREnQPDiBOpZkQUAYuNYYSIiCgYPA4j69evx5QpU5CYmAhBELBs2bIOz/nss8+Qnp6OLl26ICEhAXfddRdOnz7tzf0GlDRNA7BuhIiIKFg8DiN1dXVIT0/HvHnz3Dp+06ZNmDFjBu6++27s27cPS5cuxbZt23Dvvfd6fLOBplU7hREz60aIiIiCQePpCZMmTcKkSZPcPn7z5s3o3bs3Hn74YQBAamoq7rvvPvzzn//09NIBp1IJ0KpVaLLaODJCREQUJAGvGcnMzERJSQm+/fZbiKKIyspKfPnll7juuuvaPcdkMsFoNLZ4BAsbnxEREQVXwMPIqFGj8Nlnn2H69OnQarWIj4+HXq93Oc2TnZ0NvV4vP1JSUgJ9m7LmnXsZRoiIiIIh4GFk//79eOSRRzB37lzk5eVh1apVOHbsGO6///52z5kzZw4MBoP8KCkpCfRtyqS6EfYaISIiCg6Pa0Y8lZ2djVGjRuGJJ54AAAwePBjh4eEYPXo0XnzxRSQkJJxzjk6ng06nC/SttUkXYl/ey2kaIiKi4Aj4yEh9fT1UqpaXUaulfh7nXy8PuWbEzDBCREQUDB6HkdraWuTn5yM/Px8AUFRUhPz8fBQXFwOwT7HMmDFDPn7KlCn4+uuvMX/+fBw9ehSbNm3Cww8/jJEjRyIxMdE/34UfSWGkycppGiIiomDweJpmx44duPrqq+WPZ8+eDQC4/fbbsXDhQpSXl8vBBADuuOMO1NTU4O2338Zjjz2G6OhojBs37rxc2gs0d2HlyAgREVFwCOL5OFfSitFohF6vh8FgQFRUVECv9acPt2Lj4VN4Y/oQTM1ICui1iIiIfs3cff/m3jStcOdeIiKi4GIYacV5514iIiIKPIaRVqSaETY9IyIiCg6GkVaam54xjBAREQUDw0gr8jQNd+0lIiIKCoaRVrhRHhERUXAxjLQi9xlhGCEiIgoKhpFWODJCREQUXAwjrWjZZ4SIiCioGEZa4cgIERFRcDGMtKIL4d40REREwcQw0krzrr0MI0RERMHAMNKKXDPCPiNERERBwTDSCpf2EhERBRfDSCssYCUiIgouhpFW5JoRLu0lIiIKCoaRVuTVNBwZISIiCgqGkVa4ay8REVFwMYy0wl17iYiIgothpBUWsBIREQUXw0gr0tLeJqsNoigqfDdERES/fgwjrUhNz0QRMFsZRoiIiAKNYaQVaZoG4M69REREwcAw0krLMMK6ESIiokBjGGlFEAR5qqaJYYSIiCjgGEbawBU1REREwcMw0obmMMKaESIiokBjGGmDvHOvmSMjREREgcYw0gZO0xAREQUPw0gbWMBKREQUPAwjbWDNCBERUfAwjLRBrhnhyAgREVHAMYy0Qd65lyMjREREAccw0gYda0aIiIiChmGkDZymISIiCh6Pw8j69esxZcoUJCYmQhAELFu2rMNzTCYTnn76afTq1Qs6nQ69e/fGf/7zH2/uNyik1TTsM0JERBR4Gk9PqKurQ3p6Ou666y7ceOONbp1z0003obKyEh999BH69u2L8vJy2Gzn7xs9V9MQEREFj8dhZNKkSZg0aZLbx69atQrr1q3D0aNHERMTAwDo3bu3p5cNKjY9IyIiCp6A14z873//w/Dhw/Hyyy8jKSkJ/fv3x+OPP46GhoZ2zzGZTDAajS0ewaQLsdeMsICViIgo8DweGfHU0aNHsXHjRoSGhiInJwenTp3Cgw8+iNOnT2PBggVtnpOdnY3nn38+0LfWLq2aIyNERETBEvCREZvNBkEQ8Nlnn2HkyJG47rrr8Prrr+O///1vu6Mjc+bMgcFgkB8lJSWBvs0WWDNCREQUPAEfGUlISEBSUhL0er383MCBAyGKIk6cOIF+/fqdc45Op4NOpwv0rbVLbnrG1TREREQBF/CRkVGjRqGsrAy1tbXycwcPHoRKpUJycnKgL+8Vuc+IlWGEiIgo0DwOI7W1tcjPz0d+fj4AoKioCPn5+SguLgZgn2KZMWOGfPwtt9yCbt264c4778T+/fuxfv16PPHEE7jrrrsQFhbmn+/Cz3TsM0JERBQ0HoeRHTt2ICMjAxkZGQCA2bNnIyMjA3PnzgUAlJeXy8EEACIiIrB69WpUV1dj+PDhuPXWWzFlyhS89dZbfvoW/E/LmhEiIqKg8bhmZOzYsRBFsd3PL1y48JznBgwYgNWrV3t6KcWwHTwREVHwcG+aNrDpGRERUfAwjLRBWk3DpmdERESBxzDShuamZ6wZISIiCjSGkTZI7eC5moaIiCjwGEbawJoRIiKi4GEYaYMURpo4TUNERBRwDCNtkKdpODJCREQUcAwjbXDetddVTxUiIiLyHcNIG6SlvQDQxP1piIiIAophpA1SzQjAqRoiIqJAYxhpgzRNA7DxGRERUaAxjLRBEASnzfIYRoiIiAKJYaQdcq8RM5f3EhERBRLDSDu4cy8REVFwMIy0o7nxGcMIERFRIDGMtENa3suRESIiosBiGGkHd+4lIiIKDoaRdnDnXiIiouBgGGkHd+4lIiIKDoaRdsgFrFZO0xAREQUSw0g7mvuMcGSEiIgokBhG2sE+I0RERMHBMNKO5poRTtMQEREFEsNIO6Q+I2x6RkREFFgMI+3gNA0REVFwMIy0g7v2EhERBQfDSDu4ay8REVFwMIy0g03PiIiIgoNhpB1SzQgLWImIiAKLYaQdrBkhIiIKDoaRdrDPCBERUXAwjLRD6jPCkREiIqLAYhhpB/uMEBERBQfDSDu4moaIiCg4PA4j69evx5QpU5CYmAhBELBs2TK3z920aRM0Gg2GDBni6WWDTss+I0REREHhcRipq6tDeno65s2b59F51dXVmDFjBsaPH+/pJRXBpb1ERETBofH0hEmTJmHSpEkeX+j+++/HLbfcArVa7dFoilICOU1TcqYeS/NO4PbMXugWofP71yciIrqQBKVmZMGCBTh69CieffZZt443mUwwGo0tHsEWyNU0760/grfWHMJnW4v9/rWJiIguNAEPI4cOHcJf/vIXfPrpp9Bo3BuIyc7Ohl6vlx8pKSkBvstzadWB6zNy/HR9i/8nIiLqzAIaRqxWK2655RY8//zz6N+/v9vnzZkzBwaDQX6UlJQE8C7bpgsJ3NLe0rMNAICy6ga/f20iIqILjcc1I56oqanBjh07sGvXLsycORMAYLPZIIoiNBoNfvjhB4wbN+6c83Q6HXQ6ZWsppJqRJov9fgVB8MvXFUURpY4QUmZgGCEiIgpoGImKisLevXtbPPfOO+9g7dq1+PLLL5GamhrIy/tECiMA0GS1yatrfHW6rkkebSmvboTNJkKl8k/QISIiuhB5HEZqa2tx+PBh+eOioiLk5+cjJiYGPXv2xJw5c1BaWoqPP/4YKpUKaWlpLc6PjY1FaGjoOc+fb5zDh8nivzAiTdEA9pBzqs6E2MhQv3xtIiKiC5HHNSM7duxARkYGMjIyAACzZ89GRkYG5s6dCwAoLy9HcfGFv0okRN08WmEy+69upHWdSFl1o9++NhER0YXI45GRsWPHQhTFdj+/cOFCl+c/99xzeO655zy9bNAJggCdRgWTxebXFTWl54SRBgxJifbb1yciIrrQcG8aFwLR+OzE2XPDCBERUWfGMOKCtLzXny3hpfARobMPSrUeKSEiIupsGEZcaG585r8wIoWPob26AuDICBEREcOIC3JLeD/u3CuFkZG9pTDCAlYiIurcGEZckJbz+mtkpM5kQXW9GQAwvHcMAI6MEBERMYy44NyF1R+k4BEZqsGA+EgA9iZojX4ceSEiIrrQMIy4oPXzapoTjjCSFB0GfVgIumjtIy/lBk7VEBFR58Uw4kLz0l7/jFyUOYURQRCQGB3W4nkiIqLOiGHEBX/XjEit4JO62kOIFEa4vJeIiDozhhEX/L2aptRpZMT+//Y9aTgyQkREnRnDiAtyAavVvwWs0ohIop7TNERERAwjLsg1I37aKK+9aRr2GiEios6MYcQFf9aMmK02VBjtoSM5unUY4cgIERF1XgwjLvhzNU2lsRE20d5ivnuEDkBz7UhpdYPLnZCJiIh+zRhGXPBn0zNpiiYhOhQqlQAAiNPrIAj2kZczdU0+X4OIiOhCxDDigj+bnrVeSQPYp4F6OEZJWDdCRESdFcOIC/6sGZFGRhKdwojzx+w1QkREnRXDiAtynxE/1IyUGc4dGXH+mEWsRETUWTGMuODPpb0nWi3rlSSy8RkREXVyDCMuSNM0/mh61lbNCOC0vNfAMEJERJ0Tw4gLWj+NjIii2GKTPGfNNSOBL2CtaTTjo41FMNSbA34tIiIidzGMuOCvPiNn6prQ6Ag0CY5pGUkwa0beXXcEL6zYj3+vPRTwaxEREbmLYcQFf62mkaZoYiN18teUSCMjVTUmvxTKurLnhAEAkF9SHdDrEBEReYJhxAVpNY2vTc9ab5DnrGuXEIQ6rlNhCOxUzYGKGgDA/nIjrDZ2fCUiovMDw4gLWrV/mp61t5IGAARBCEqvkTN1TaiqMQEA6pusKDpVF7BrEREReYJhxAV/9RmRQkZyGyMjgHPdSOBGRg5UGFt8vK/MELBrEREReYJhxAW5ZsTH1TSupmkAIFEf+CLWQscUjWRfmbGdI4mIiIKLYcQFnZ/2pmmvx4gkMQgraqQwEh9lX83DkREiIjpfMIy4IO/aa7VBFL0v+Cx1UTMCNHdhDWTNiFS8esPQJABAQanRp+/JEzuLz+LqV3OxqqAiKNcjIqILC8OIC1LTM8D70ZH6JgvOOpqMtTdNE+heIzabiIOV9jAyZXAiQtQCDA1mubA20F79vhBFp+rw+bbioFyPiIguLAwjLjj3BPE2jEgBI1KngT4spM1jEp0KWAMxWnHibAPqm6zQalToHxeB/nGRAIJTN1JYUYOfj5x2XM8QtNEYIiK6cDCMuBCiFiAI9j97u6LG1bJeSbzePk3TYLaiOgCt2qWVNH17RECjViEtUQ8gOHUj/918TP7zqdomnHQsLyYiIpIwjLggCEJz3YjXIyP25brtTdEAQGiIGt0jdAACUzciFa8OiLePiAxKigIAFJQGNowY6s3I2VkKAAgLsY8ysXCWiIhaYxjpgK+Nz0qr6wG0v5JGIhWxBqJu5ICjXuRiKYzIIyOBnaZZmleCBrMVA+IjMXFQnP2apVxSTERELXkcRtavX48pU6YgMTERgiBg2bJlLo//+uuvcc0116BHjx6IiopCZmYmvv/+e2/vN+h0Ib71GuloJY0kkL1GpJERKYwMTIiEIAAna0w4WROYRmtWm4iPNx8HANx+Re+gBSAiIrrweBxG6urqkJ6ejnnz5rl1/Pr163HNNdfg22+/RV5eHq6++mpMmTIFu3bt8vhmleDrzr3uTNM4f77Mz/vTmCzNrd8HxNunZ7poNbioRwSAwIWDnw6cRPGZeujDQjB1SFLz1BCnaYiIqBWNpydMmjQJkyZNcvv4N954o8XH//jHP7B8+XJ88803yMjI8PTyQedr47OOGp5JAtVr5PDJWlhtIvRhIYiL0snPpyVG4fDJWuwrNeDqi2P9ek2guXB1+ogUhGnVGJRgHxk5cbYBhnoz9F3aXllERESdT9BrRmw2G2pqahATE9PuMSaTCUajscVDKdLyXm8KWC1WGyqM9pGO5A6maQLVa8R5ikaQlgahuW6kIAA1HIdP1mLDoVMQBOC2y3sBAPRdQuS/g33lHB0hIqJmQQ8jr776Kmpra3HTTTe1e0x2djb0er38SElJCeIdtqT1YWSkssYEq01EiFpAjwidy2MD1RK+9UoaiTRtEohg8LFjVGTCwDikxHRpvmai/Zr7WTdCREROghpGFi1ahOeffx5LlixBbGz7UwNz5syBwWCQHyUlJUG8y5Z8qRmRilcT9GFQqQSXx0ph5GSNyetlxG050Kp4VSJNm5ScsU+b+Iux0Yyv8k4AAO64oneLz6XJozEcGSEiomZBCyOLFy/GPffcgyVLlmDChAkuj9XpdIiKimrxUIovq2ncXdYLAN3CtdBqVBBFoNLovyLW9kZG9F1CkBLj/2mTL3ecQF2TFf1iI3DFRd1afE4ejeHICBEROQlKGPn8889x55134vPPP8fkyZODcUm/cd4sz1PurqQBAJVKQKLev0WshnqzXLMitYB3Jndi9VPdiM0mylM0M67o3aJGBWiuUzlSVYuGJu9WJxER0a+Px2GktrYW+fn5yM/PBwAUFRUhPz8fxcX2TdDmzJmDGTNmyMcvWrQIM2bMwGuvvYbLLrsMFRUVqKiogMFwYQzVyzUjZs/fPN1pBe/M33UjUhv4pOgwRIaeu3pFquHw13LbdYeqcOx0PSJDNbgxI+mcz8dG6tA9Qgub2HxvREREHoeRHTt2ICMjQ16WO3v2bGRkZGDu3LkAgPLycjmYAMD7778Pi8WCrKwsJCQkyI9HHnnET99CYPmytFca4Uh2Y2QE8H8YKaxse4pGMijJv43I/vvzMQDAtGEpCNedu2pcEARcwuZnRETUisd9RsaOHety59WFCxe2+Dg3N9fTS5xXpKW93oQRKVS4M03jfFxptX9qRtorXpWkOU2b1DdZ0EXr8X8OsqJTdcgtrIIgADMye7V7XFpiFNYfrOIeNUREJOPeNB3wdjWNKIput4KXJPl5f5oD5fbRh/bCSI9IHWIjdRBF4Jdy30YqpFGRqy+ORe/u4e0ex7bwRETUGsNIB3Qh3u3ae7bejAZHnUmCozC1I/6cphFFEQcrawE0t4FvS5ofpmpqTRZ86VjOe3ur5bytSXUqBypqYPaiKJiIiH59GEY6oPNy114pUHSP0CHUsTy4I85hxNVUmDtOnG1ArcmCELWAPj1cjVQ4ilh96P3x9c4TqDVZ0Kd7OEb37e7y2J4xXRCh06DJYsORqlqvr0lERL8eDCMd8LbPiKcraYDmnXvrmqwwNlg8ul5rUn+Ri3pEIETd/svs67SJzSbKUzQzMnt12NxNpRJwiRyAOFVDREQMIx3ytmbE05U0ABCmVSMmXNvifG9JK2naqxeRpDkakR2srPGqy+zGw6dwpKoOEToNfj8s2a1zpNEYFrESERHAMNIhb5ueNa+kca9eRJLopyLWjlbSSJKiw6APC4HZKuJQpefTJtKoyB+GJbfZy6QtwSpitdpE5Ow6gaoaU0CvQ0REvmEY6UBz0zPPwoi8ksaDkRGgeaqm3ODjyIijqVh7PUYkgiDIoyOejlQUn67H2sKTAFwv521NGhn5pcwIm8232hhXPt58DI9+sRtzvt4TsGsQEZHvGEY64G2fEWmaJalrlw6ObMkfvUaaLDYcraoDAFzsYiWNpHkDO89GKv6zqQiiCIzp3wN9ekS4fV7f2AhoNSrUmCwoOVvv0TU9sSy/DACw7mCVXzcDJCIi/2IY6YC3NSPSNIunIyNJfljee6SqFhabiMhQjbzfjSuXeNEW/mRNIz7fZu+0++fRfTy6vxC1Sh6xCVQRa8mZeuwuqQYAmK0ifthfEZDrEBGR7xhGOiD1GfFkZKShyYrTdU0AvJim8UMYcd6pt/VmdW2Reo38Um6E1c1pkw83FMFksSGjZzRG9e3W8QmtBLqIdcWecgCA9O2v3FsekOsQUGFoRNZnO/GJY5NEIiJPMYx0QJqm8aTpmTRFE6HTICrMsxbr/ihgdbd4VZLaLRxdtGo0mm046kbvjzN1Tfh0y3EAwMPj+rkVeFoL9B41K/fap2juHpUKANh46FTQpmqKT9fjN2+sx4JNRUG5npIOVBhxwzubsHJvOV5c+QuMjZwOo/NXVY1J/mWNzi8MIx3QerFRnvMUjadv1NJISoWxERYvO5RKxavu1IsAjt4fCdJIRcfh4D8bi1DfZEVaUhTGXtzDq3t0HhnxtcFba8dO1aGg1Ai1SsCDV/fFgPhIWGwivg/SVM37G47gQEUNXl99EI1e7PZ8odhwqAp/mL8Z5QZ7fZPJYsPKPRyBovOT2WrDTe9txm/eXI/V+yuVvh1qhWGkA3LNiAdvKqVeLusF7B1bQ9QCbCJQ6eWSVOdpGndJUzUddWI1NJjl5bwzr/ZuVAQABsZHQSUAp2qbcNLPS29X7LGPilxxUTfEhGvx28EJABCUN8r6JguW77Jfv6bRgu8Kfp1vzkt2lODOBdtRa7LgstQYPDj2IgCQtwUgOt/k7CpF0ak6iCLw2JJ8FJ8OXPE8eY5hpAPerKbxdIM8ZyqVgAS993UjhgYzyhy/qfaPcz+MuFvE+t+fj6HGZEH/uAhce0mcx/cnCdOqcZFjBY6/60akepEpgxMBANddag8jmw6fQnV9k1+v1da1a0zN3XMXbysJ6PWc2WwiPtly3KfW/h0RRRGv/1CI//tyDyw2EdcPScTHd4/EHVf0hkoA8o6fRdGpuoBdn8gbFqsN7/x0GIB9+tzYaMGDi/J+1SOXFxqGkQ7ITc+8mqbxbFmvxJe6kYOOzquJ+lDow9xrQgY0L+/dV2Zsd9qk1mTBfxx1EFlX9+2w9XtH5KkaP66oOXyyBgcqahCiFjBxUDwAoE+PCAxMiILFJuKHfYEdnl3sWGE0I7MXBAHYWnQmaG/OS/NK8NdlBbjto60BafTWZLHhsSW78dZa+w/1mVf3xRvTh0CnUSM2KhRj+tun7L7i6AidZ77ZU4Zjp+sRE67FsqxR6NolBAWlRvxtxX6lb40cGEY64E3NyAkfpmns50m9RjwPI54Wr0r6xUVAq1ahptGCkjNtX/fTLcdRXW9Gavdw/NYx6uCLQHRi/Wa3fVTkyr7doe/SHMYmX2oPJoFcVXOwsgY7i6uhUQmYOa4vrnK8OS/ZEfjREZtNxAcb7EHxbL0Zzyzb69daHEODGXcs2Iavd5VCrRLw0o2X4vGJF7eYpvuDYzuAr3eeCGgzOyJPWG0i3nYE6LuvTEXf2Ai8cXMGBAFYtLUYX+9keD4fMIx0wLkdvLs/YKVpmmQvpmkA33qNeFq8KglRq+QA09a0SUOTFR9uOAoAeHDsRVD7OCoCOI2MlPtnWkEURblepHVYCsZUjdR3ZfzAWMRGhuLmESkA7HUUZi+Lkd217mAVDp+sRRetGhqVgO/3VeJ/u8v88rVPnK3HtHd/xs9HTiNcq8Z/7hiBm0f2POe4CQPjEBWqQZmhEZuPnvbLtYl89e3echypqoM+LETuFH1V/x54eFw/AMDTOQVcYXMeYBjpgLRrL+De/jRWm4gKo71mw/tpGimMeN6F1ZviVYnUFr6tupHF24txqrYJyV3DMDUjyeOv3RZpZKTkTINflt0WVtbgSFUdtGoVrhnUsp4l0FM1jWYrcnaVAoD8Rj1uQBy6R2hRVWPCTwdO+v2azj5wBMVbRvbEw+PtP2TnLt+Hk0bvO/kC9oLmG975GQcraxEfFYql918hj/i0FhqixpR0ewhkISudD2xOoyJ3jUptsX/Ww+P7YXS/7mgwW/HAZ3moNfm2Uzr5hmGkA9LICODe/jSVxkZYbSI0KgE9InVeXdPbxmeiKHo9TQM09/5o3RXVZLHivXX2N7sHxl6EELV//rPRdwmRR4/8MTqywjFFc9XFPRDVxqZ90qqaFQGYqvl+XwWq681Iig7DmH72N2utRoUbh9qnLr7YHripmoJSA34+chpqlYA7r0zFA2MvQlpSFAwNZjyV4/10zfZjZ3DTe5tRVWPCgPhI5GRdIRc6t0faufm7gnLUsOcIKeyH/ZUorKxBpE6DO0b1bvE5tUrAG9OHID4qFEer6vCXr/b4vc0AuY9hpAMalQBpRsJk7bjyWqrzSIgO9XoqI8lRa+JpzUi5oRE1jRZoVIK8UsUTae30/vgy7wQqjI2IjwqV6wL8RZqq2e9j3UjLKZqENo9xnqo5W+ffqRppimba8OQWr/tNw+1TNT8VnkSFwbdRivZI02eTL01AUnQYQtQqvDZtCELUAn785aQ8YuOJ3SXVuHPBdtQ3WTGqbzcsvT9TXuXlSkZKNPr0CEej2Ybv9rIFPylHFEX8e+0hAMAdo3q3WdDfLUKHebdmQKMSsGJPOT5xNHOk4GMY6YAgCB7t3OvtnjTOpB/6NY0WjzpaSlM0fXqEy/fsiYEJUVCrhBa9P8xWG+bnHgEA3HdVH3mps7/4q4h1X5kRx07XIzREhQkD215ynNo9HJckRMFq8+9eNUWn6rDl6BmohObwIekbG4ERvbvCJgJfBaBQrqy6QV7KfK/THkEXx0di1oT+AIDn/rfPoyD0S7kRM/6zDbUmCzL7dMNHt49oMbztiiAIcmAN9FSNxWrDS98dkFcwETlbe+Ak9pUZEa5V4y5HJ+a2DOsVgznXDQQAvLBiP/Ide1pRcDGMuMGTXiMnzkorabwPI+E6jZziyz2oG2meovGseFUSGqLGRT3CATQ3P1u2qxQnzjage4QWN484t2jRV3Kdio+9Mb5xjIqMGxCLcF37LfgnS1M1fmyAtni7/c3wqv492nzdpzv+3r7YXuL3VSYLfz4Gi03E5X1icGmyvsXn7hvTB+nJehgbLZjztXtD0IdP1uJPH26FocGMoT2j8eHtwxEa4lkAvSEjCYIAbDt2BsdPB25Z84cbi/DuuiOYk7MXO4vPBuw6bTlUWYOSM2yadb4SRVFegn5bZm90Dde6PP6uUb0xKS0eZquIrM92+n3klDrGMOIGT3bulaZWkn0II4B3dSMHHCtpvClelTj3G7HaRLzjGBW5Z3QfhGn9OyoCNI+MHKmqRUOTdw2IRFGUu6t2tOR4smOq5ucjp/3yA6fJYpP7arS1wgQArrs0HhE6DYrP1GNLkf9WmdQ0mvH5VnsQureNnZM1ahVenZYOrUaFnwqrsLSDkYrjp+tw64dbcLquCWlJUVh410iXwa49CfowXNm3OwDgq52eTxG54/jpOrzx40EAgCgCc77aG/AVS5LdJdWY9OYGXPfWBq+W31PgrT90CrtLqhEaosI9o9sfFZEIgoCX/zAYqd3DUVrdgEeX5HN5epAxjLhB2rnXncZnvnRfdeZN3Yg0TXOxB51XW5M7sZYasGJPGYpO1SG6Swj+dHkvr7+mK7GROnSP0MImNocpT+WXVOPE2QZ00apx9cWxLo/t3T0cgxLtUzXf7/N9qmbNL5U4VduEHpE6jBvQ9rW7aDX43RB7SPJnIesX20tQY7KgT4/wdr/vfnGRmH2NfbrmhW/2txtuy6obcMsHW1FpNOHiuEh8ctdlbRYBu0uaqvkqz/89R0RRxNM5BWg02zCid1fEhGtRWFmD99cf9et12tLQZMWjS/JhsYmoabTgiaW7g/amZbbaMHd5AZ5dXuD1vlWdgSiKeGuNvVbk1st6oXuEewsJIkND8M6tQ6HTqJBbWIV3cg8H8japFYYRN2jV7jc+K6v2fZrG+Xx3R0bMVhuOOHbc9WYljcR5j5p5PzUviYvw4jdkdwiC4PMOvtKoyPiBcW6N3kiFrP5ogLbIUa9w0/Bkl6uMpJ4j3xVU+KXPicVqw4JNxwDYR0VcdcO9d3QfZPSMRo3JgifbWDFwsqYRt364FaXVDejTPRyf3DOyw2Htjlx7STwidRqUVjdga9EZn75Wa1/vLMXGw6eg06jwyh/S8dff2uf731xzKODdbv+56gCOVtWhR6QOYSFq/HzkNP67+VhAryl59ftCfLz5OP67+TheX30wKNcE7AHsjgXbMHXeJpyu9X9nX1csVpvHLds3HzmNvONnodWocN+Yc0cMXRmYEIUXpqYBAF5ffRDrDlZ5dD55j2HEDe7WjIiiKI9k+FLACngeRo5W1cFsFRGh03jdbA1oHhkpMzTiYGUtInUa3H5Fb6+/njucd/D1lM0myqGivVU0rTlP1ZzxYaqm5Ew9Nh4+BQCYPtx1Pc2lSXoMTIhCk8WGZV6sbmnt24IKlFY3oFu4Fjd00PdFrRLw6rR06DQqbDh0CoudRmfO1DXhTx9uRdGpOiR3DcOn91yG2EjvOgc7C9Oq8dt0+9+zPwtZT9ea8OJKewvvRyb0Q+/u4Zg6JAmj+3VHk8WGp31YytyRDYeqsNCxSeSr09Lx1HUDAAAvfXdA/kUgUH7YV4H3nEZ+3sk9EvDeNYD9Z9oTX+5GbmEV8kuqkbVoZ9Cmwwz1Zkx5exOGvrAaH6w/6vZo0FuOFTR/HJGC2CjP/1u+aXgKbh6RApsIPLRoJ46dR3stmSxWHD9dh5+PnMK2ojO/qqXIDCNukKZpOtq5t7rejHpH3YP/RkbcK2CVpjj6x0V4vZMuAESFhqBXt+Zmbbdf0faSOH9K82FkZGfxWZQbGhGp07TbjKu13t3DkZbk+1TNkh0lEEV76/me3Vw3uBMEAdOH26cuFm8v8emHiCiK+MDxxnRbZi+3Ckwv6hGBJyZeDAB4ccV+nDhbD0ODGbd9tFVuaLbonst9/u/W2e+HNvccqfNTQ6kXV/6Cs/VmDIiPlOtkBEHA36deitAQFX4+cjogdSqGejOeWLoHAHDb5b1wVf8e+NPlvTC6X3eYLDbMXrI7YFMnxafr8djS3QDso5S3O7qIProk36suzZ54J/cIVuwph0YlIFyrxpajZ/D3lb8E9JqA/U33z5/swC/lRtQ3WfH3b3/B797ehN0drHTZVnQGW46eQYhawH1XXeT19Z+/fhCG9oyGsdGCez/eEbSGaBarDbtLqvHd3nJ8tLEIL6zYjwc+zcP1b2/EiL//iIufWYWrXsnFLR9sxU3vbca0dzf7faNRpTCMuEHn5v400qhI9witxysQWvO0ZqTQx5U0zqRw0EWrxl1Xdlz85StpZORARY3Hv3VJq2KuuSTOo79zaarmWy+naixWm7znzM0jUzo42m5qRhK0GhUOVNRgrw+rh7YWncHeUgN0GhVu86CW585RqRjeqyvqmqx4fOlu3LFgG/aVGdE9QotP77msw0DlqWG9uqJ3ty6ob7LiuwLf63PWHaxCzq5SCALw0u8Ht5gW69mtCx4Zb6+NeXHlfr9PJ8z9XwEqjI1I7R6OOY4REanoMTJUg90l1fISeH9qNFvx4KI81DRaMLRnNP4yaQCemjwQg5P1qK43Y2YARyp+3F+JV38oBGB/c/7X9CEA7Cu4Arnfks0m4v++3IOtRWcQodPgiYkXQx8Wgv3lRkx9ZxOe+9++dhvqSX1Fpg1P8SlY6zRqvPunYYiL0uHQyVo8+kXgC1pLztTjt//eiOvnbcIDn+3ECyv246ONRfiuoAK7TxjkzS9DQ1To0yMcYSFq7Dh+FlP+vRFzlxf4pYu1khhG3CBN03RUwOqvKRqgeWSkwtHRtSO+tIFv7aqL7SMM94zugxgfawfc0TOmCyJ0GjRZbB4Nd1udp2jS3Zuikfg6VZNbWIVKowkx4Vpcc0nbfU1ai+6ixaQ0+4Z9i30oZJWanP1+WDK6uVmcB9ina16Zlo7QEBW2HD2DXcXV0IeF4JO7L0PfWM+b5HVEEAR5dOTLPN/evOqbLHg6Zy8A4I4remNISvQ5x9wzOhUD4iNRXW/262/vK/aUYXl+GdQqAa/flI4u2ub6qQR9GP52/SAA9poVX5eot/a3FftRUGpE1y4hePuWodBqVNBp1Jh3y1BEhmqws7gaL6864NdrAvaly7O+yIcoAn+6vCduvawXrh0Uj1kT7FsNPJNTgF0BWk792upCLM8vg0YlYP6fhiLr6r5Y89hVuCEjCaJoD0MTXl+HVQXlLUYYdxWfxYZDp6BRCXjAh1ERSWxUKN67bTi0GhVW76/EG46i2EDYVnQG18/bhAMVNYjQaZDRMxqTByfgz2P64Lkpl+C924ZhxUNXYudfr8Evf/sN1j42FmseuwqTByfAJgIfbz6Oca/lYkkA2gcEC8OIG9zduddfK2kAIDbS3sHVahNxsqbjqRpf2sC3Nm1YMnIfH4tHHT94Ak2lEnBJgqNupNT9qZptRWdQVWOCPiwEV/Z1b4pG0qubb1M1Um+R3w9N8qgR3HRHIes3+WWob/J86PdIVS1+/MVeK3C3F6NWqd3D8eRv7L/ZR+o0+OTukRiY4PtoWntuHJYMQQC2HD3jU1+ON348hBNnG5AUHYbHr724zWNC1Cq89PvBEATg612l2HDI9+LDSmMjns4pAABkjb0IGT27nnPM1CFJ+M2geFhsImYvyfe44LI9ObtOYNHWYggC8MbNGS1+00+J6YJXp6UDAD7YUIQf/LAyTGKoN8tTEyNTY/DslEHy5x4e1w/XXhKHJqsN93+a59bPJk98vq0Y836yjzD948ZLMdqxtUL3CB3+NX0IPr37MvTq1gWVRhPu/3Qn7v14h/xL4L8dfUVuyEhCSox/RvmGpETjHzdcCgB4a80hrCrw/1YSX2wvxq0fbsEZx5L6Hx4dg5wHR2HeLUPx1HUDcceoVEwcFI+0JD1iwrXyNHxidBjm3TIUn91j/2XidF0T/u+rPbhx/s/Ye+LCm7phGHGDNE3z9tpD+M0b6zHh9XW46pWfcEX2Ggx/8UcM+dsPGDR3Ff7+rf23sUQ32mZ3RK0SEO8ovupoXrim0Sz/g/THyIggCOjdPdyn2hNPDXKxSV97pPbvEwfFedVxdvKl9uW2Kz1sgFZhaMRaR/HgdA8bwV2e2g09Y7qgxmTBt160S/9oYxEA+w653rT8B+wjCx/MGI5vHroSg5Ojvfoa7kqKDsMVF3UDYF8F442CUoM8GvTC1EEue58MSYnG7Zm9Adh3Y/W2dw0gFW/ugaHBjEuT9HhofNvhXBAE/P2GNHSP0OJgZS3+5YeVLgcra/DU1/YQ9NC4fm3WQ00cFI97HIH0saW7/dKEzWK1YebnO3HsdD2SosMw/9ahLabDVCoBr08fgn6xEag0mvDApzvd6r/kjtzCk3hmmf17fnh8v3O6GQPAlf264/tZYzDz6r7ydgfXvL4OL6zYj7UHTkIlAFlX9/XL/Uj+MCxZ7uA6e8lur1sQtGax2vD8N/vw5Fd7YbaKmDw4AUvvu8Lj6aVRfbvj24dH46nrBiBcq0Z+STV+N28jnsrZe0E1b2MYcUNPR8ouMzTiQEUNDp+sxfHT9SgzNOJUrQnV9WbUNVlhtYlQqwSM6tfdL9eVpntKOyhiPVhpHxWJi9Ihukvgp1UCwdO28BarDascdQiTO2h01h5pqmbz0dMe1Rgs3VECmwiM7B3j8fSGSiXIoyNfbPesjfnpWpPcYO1eNxo5tUcQBFxzSRx6dw/3+mt4Qpqq+WrnCY8Ldy1WG/7y9R7YRPtqqXEDOp4Se3zixUjQh6L4TD3e9GFo/dOtxVh/sApajQr/mp7ucul2twgdsm8cDAB4f8NRbD/m/XLmOpMFD3yahwazFVf27Y5H2glBAPDkpAH2ZduNFmQt8j0YvPTdAWw4dAphIWq8P2NYm9OAEToN3p8xHJGhGuQdP4vn/rffp2sC9pV0WZ/thNUm4sahSS5HZUND1Hh84sVY+fBojOjdFfVNVjmkXz8kKSD/XT913QCM6tsN9U1W3PvxDp/f5A0NZty5cLu8PH/2Nf3x9h8zvG4sqdWo8OcxF2Ht42Nx/ZBEiCKwaGsxrn4tF59tPR60FVC+CEzziF+ZRyb0w2V9usFqsyFErXI8BKc/N38cEarxqVmUs0RHEeujX+Tj6Zy96KJVo4tWg9AQtePPaoSFqHHa8Q/DH8WrSpGKWH8pM8JmE132zQDsw/6n65rQtUuI/Ju3p3p264JLk/TYW2rA9/sqcctlHY9y2GwivvCwcLW1PwxLxms/FGL7sbM4fLLW7UDzyZbjMFlsGJysx8jUGK+urYTfpMXjr8sKUHymHtuPnfXo3hdsOoaCUiOiQjWYO+USt86J0GnwwvVpuOfjHfhgw1H8Lj2xw92GWys6VYd/OOpOnvzNAPSN7XjE8ZpL4vCHYcn4Mu8EHluyG989MtrjDraiKOIvX+/Fkao6xEeF4s2bh7jccDNErcLbtwzF5Lc2YM8JA/6x8hc8f32aR9eUfJV3Ah863tRfnZYu/4LQltTu4Xjrjxm4a+F2fL6tGGlJUbj1Mu8aI5ZVN+CuhdtR12TFFRd1w0s3DnZrVLZ/XCS++HMmluwowT++/QVWm+j3URGJRq3C238cit/N24iSMw2Y+flO/PfOkdB4sYP50apa3PPfHTh6qg5hIWr8a3o6fpPmWc1be+KiQvHmzRn448ieeHb5PhRW1uDpnAK889MR/HlMH0wfkeLz4opA4ciIG3QaNa7q3wPjBsRhdL8euLxPNwzrFYPBydEYmBCFvrER6NUtHInRYX4LIgBw9YBYqAR7oWZNowWVRhOKTtXhl3Ij8o7bi7V+2F+JvOP2QrLBSe3/8Djf9Y2NgFajQo3JgpKzHQ83S1M0v0lLcPkba0eaG6CVuXX8xsOncOJsA6JCNfK5noqLCpW7tS51c1VCo9mKTzbbdxS9d3SfoE6h+aqLtvnvypNC1pIz9XJzr6cnD/So/8mES+IwKS0eVpuIOV/vcasIXGKx2vDoF/loMNvfHO/0oM/O3CmXICk6DMVn6uVpW098uuU4vtltL5Z9+5YMtwqUk6LD8K+bhgAA/rv5uMfTjoC9+HOOo0D4oXF95T2cXLn64lh5ufizy/d5NRpkbDTjzgXbUWk0oX9cBOb/aZhHU64qlYCbR/bE5jnj8dMTYwNSiC3pGq7FBzOGo4tWjU2HTyP7O88Lh9cfrMLUeZtw9FQdkqLD8OUDmX4LIs4u79MNKx6+EnN/ewm6R2hRWt2AZ/+3D6NeWot5Px2GoeH8W3nDMHIeu35IEvY8NxGb54zDmseuwoqHrsSS+zKx8M4RePdPQ/H6Tel4cWoanr5uIOb+9hLc62G3wfNJiFolt7Ev6KCI1Wy1YZWjYG+Km43O2iNP1Rxxb6rmc0fH1Rsyknz6DUOaD/9q5wm3thn4emcpTtc1ISk6TF6RcyGR2sOv3FPuVuGuKIp4elkBGsxWXN4nps36gY4897tBiNRpsPuEAR970CV1fu4R5JdUI1KnwSvT0jscpXMWFRqCV6bZp2sWbS3GT4XuNybbXVKNF1bYA8ycSQMwvLf7I0hXD4jFA2PtK0ie/GqPR51oK42NuO+TPDRZbJgwMA6POnZ7dscDV12EyYMTYLGJeODTPJQb3O97Yrba8OCnO1FYWYPYSB0W3DnS655G4TqNX5r1dWRAfBRecxQOf7SxSJ427YgoivjPxiLcsWAbjI0WDO/VFctnjnI5+uSrELUKd12Zio1PjsML1w9CUnQYTtc14ZXvC3HlS2vx0ncH5OXC5wNB9HASd/369XjllVeQl5eH8vJy5OTkYOrUqS7Pyc3NxezZs7Fv3z6kpKTgmWeewR133OH2NY1GI/R6PQwGA6KiLtypCHJtztd78Pm2EkR3CUG4VgNRFGEVRdhE+z9mm2gfJbLaRNSaLOgeocPWp8a7HMZ2x+/e3og9JwyYfGkC+vQIh81xLZsoQhTtUzPSx59uOQ6LTcR3j4z2aRWK2WrDFS+tRVWNCc9MHohLk/QQ4XTNFvcg4sUVv+DoqTo8M3kg7mljU7zznc0mYuyruSg+U49/TU/HDRnJLo9ftqsUs77Ih1ajwqpHRqOPl8W6n245jmeWFSBcq8bq2Vd1WBxYUGrA1HmbYLGJeP2mdNw41PV9tue5/+3Dwp+PITZShx8eHdNhLVd1fRMmv7URpdUNmDgoDu/+aZjHo18Wqw23fLAV246dwcCEKOQ8eEWHgbnRbMX097dgd0k1+sVG4OsHr0Ckh6O79U0W3PjOzzhQUYPByXosuS+zw+tKxcFf5p1AF60aS+7LlLeiuBC8/kMh3lp7GFqNyn7viVE4XdeECkMjKo2NqKwxodLpz2XVDTh80t62YNqwZLx4Q5pHq/D8wWy14ZvdZZifewSHHPei1ahw0/Bk3DfmIr+tQGrN3fdvj8PId999h02bNmHYsGG48cYbOwwjRUVFSEtLw/3334977rkHa9aswaxZs7By5UpMnDjRr98MXdhW7ilH1qKdbh//0Li+eKydZZ6eeG/dEY+GXIekRGNZ1iifr/vPVQc8apQVGarB5jnjA7ZPUKC98eNBvPHjIahVAkLUAgQIEARAAOQ3XsHxPw1NVlhsIh6/tj9mjvN+ibnNJmLae5uRd/wsYsK18m/e8tu80/u9AKCqxgRjowWT0uLxzq1DvZ4Oa2iyYvK/N+BoVR36x0XIIcj5p63zD97Ss/U4UlWHXt264JuHrvR6urfS2Ijr3tyA03VNuLxPDHp3C7cHeFGEzSbC6gjXFpsNVhtQYWxAQakR+rAQ/G/mKPTq5l3xZ8mZevzu7Y04W29GZp9u6B8XIYfp5l8mpD8Dp2pNWHewCmqVgA9nDMfV7Wwyeb6y2UT8+ZM8/PhLJbRqFSw2GzqaCVQJwFPXDcTdV6YqOs1qs4lYc+Ak3sk9jF3F1QDsqzd/l56IB8dehH4+bLTaloCFkRYnC0KHYeTJJ5/EypUrUVBQID938803o7q6GqtWrXLrOgwjnYMoijh8shY1JgvUggCVYH+zUgkCVCpALQgQBAEqwZ7ok6LD/PKPur7Jgnd+OgJjo7nlNR3/Lzj9WaMWMNVPFfsnjY24/9M8nK03n3NNoPn7VgkC1CoBMzJ7dTiicD4rq27AxDfWo6bRvf4qgxKjkPPgKK+WbTs7WFmDKf/e6NZGl4B9J+lVs8b43PAvv6Qav5//s9v1KjqNCl8/eIXPQ/cbDlVhxn+2wd2f7CoB+Piuy3Clj6sANx0+hRn/2eZRfc7fb0jzuvBVaTWNZvx+/s84WGkfZVCrBPSI0CFOH4q4SB3iokIRrw9FbKQO8fpQ9I2NQIIf2j74iyiK2HL0DN7JPYwNh+x7bL1w/SDc5lga7y/nTRgZM2YMhg4dijfeeEN+bsGCBZg1axYMhrZ7SphMJphMzXNZRqMRKSkpDCNEF7j6JgvO1DXJb5SiCIgQHf9v/wEp/UBK7hrmt6HssuoGlFU3yF+7+fr2Pzg/3z8uwqPOtq7sLqmWh8SdtRWhR6bG+G2o/KcDJ7H7RDU0KgEqlQC1I9BKwbb5OWBISle/NEsEgB3HziC3sAoqAY4QL4X75o/tf7Yv5x/V1z9tEJRSZ7Lg2Gn7Ls7dwnU+TxkrZa+jruqFqWl+X23jbhgJ+HhvRUUF4uJa9gaIi4uD0WhEQ0MDwsLOTYrZ2dl4/vnnA31rRBRkXbSaFu3UgyUxOsyvmwC6Kz0lGulttK4PtKsHxCoy9TG8d4xHhbcXunCdJqBFqMFyabIerzgKc5VyXq6mmTNnDgwGg/woKQncpkxERESkrID/ihIfH4/KysoWz1VWViIqKqrNUREA0Ol00On8M0xKRERE57eAj4xkZmZizZo1LZ5bvXo1MjMzA31pIiIiugB4HEZqa2uRn5+P/Px8APalu/n5+SgutjeDmjNnDmbMmCEff//99+Po0aP4v//7Pxw4cADvvPMOlixZgkcffdQ/3wERERFd0DwOIzt27EBGRgYyMjIAALNnz0ZGRgbmzp0LACgvL5eDCQCkpqZi5cqVWL16NdLT0/Haa6/hww8/dLvHCBEREf26+bS0N1jYZ4SIiOjC4+7793m5moaIiIg6D4YRIiIiUhTDCBERESmKYYSIiIgUxTBCREREimIYISIiIkUxjBAREZGigr99phekVihGo1HhOyEiIiJ3Se/bHbU0uyDCSE1NDQAgJSVF4TshIiIiT9XU1ECv17f7+QuiA6vNZkNZWRkiIyMhCILfvq7RaERKSgpKSkrY2fU8wdfk/MLX4/zC1+P8wtejY6IooqamBomJiVCp2q8MuSBGRlQqFZKTkwP29aOiovgf0nmGr8n5ha/H+YWvx/mFr4drrkZEJCxgJSIiIkUxjBAREZGiOnUY0el0ePbZZ6HT6ZS+FXLga3J+4etxfuHrcX7h6+E/F0QBKxEREf16deqRESIiIlIewwgREREpimGEiIiIFMUwQkRERIrq1GFk3rx56N27N0JDQ3HZZZdh27ZtSt9Sp7B+/XpMmTIFiYmJEAQBy5Yta/F5URQxd+5cJCQkICwsDBMmTMChQ4eUudlOIDs7GyNGjEBkZCRiY2MxdepUFBYWtjimsbERWVlZ6NatGyIiIvD73/8elZWVCt3xr9v8+fMxePBguZFWZmYmvvvuO/nzfC2U9dJLL0EQBMyaNUt+jq+J7zptGPniiy8we/ZsPPvss9i5cyfS09MxceJEnDx5Uulb+9Wrq6tDeno65s2b1+bnX375Zbz11lt49913sXXrVoSHh2PixIlobGwM8p12DuvWrUNWVha2bNmC1atXw2w249prr0VdXZ18zKOPPopvvvkGS5cuxbp161BWVoYbb7xRwbv+9UpOTsZLL72EvLw87NixA+PGjcP111+Pffv2AeBroaTt27fjvffew+DBg1s8z9fED8ROauTIkWJWVpb8sdVqFRMTE8Xs7GwF76rzASDm5OTIH9tsNjE+Pl585ZVX5Oeqq6tFnU4nfv755wrcYedz8uRJEYC4bt06URTtf/8hISHi0qVL5WN++eUXEYC4efNmpW6zU+natav44Ycf8rVQUE1NjdivXz9x9erV4lVXXSU+8sgjoijy34e/dMqRkaamJuTl5WHChAnycyqVChMmTMDmzZsVvDMqKipCRUVFi9dGr9fjsssu42sTJAaDAQAQExMDAMjLy4PZbG7xmgwYMAA9e/bkaxJgVqsVixcvRl1dHTIzM/laKCgrKwuTJ09u8XcP8N+Hv1wQG+X526lTp2C1WhEXF9fi+bi4OBw4cEChuyIAqKioAIA2XxvpcxQ4NpsNs2bNwqhRo5CWlgbA/ppotVpER0e3OJavSeDs3bsXmZmZaGxsREREBHJycnDJJZcgPz+fr4UCFi9ejJ07d2L79u3nfI7/PvyjU4YRImpbVlYWCgoKsHHjRqVvpVO7+OKLkZ+fD4PBgC+//BK333471q1bp/RtdUolJSV45JFHsHr1aoSGhip9O79anXKapnv37lCr1edUO1dWViI+Pl6huyIA8t8/X5vgmzlzJlasWIGffvoJycnJ8vPx8fFoampCdXV1i+P5mgSOVqtF3759MWzYMGRnZyM9PR1vvvkmXwsF5OXl4eTJkxg6dCg0Gg00Gg3WrVuHt956CxqNBnFxcXxN/KBThhGtVothw4ZhzZo18nM2mw1r1qxBZmamgndGqampiI+Pb/HaGI1GbN26la9NgIiiiJkzZyInJwdr165Fampqi88PGzYMISEhLV6TwsJCFBcX8zUJEpvNBpPJxNdCAePHj8fevXuRn58vP4YPH45bb71V/jNfE9912mma2bNn4/bbb8fw4cMxcuRIvPHGG6irq8Odd96p9K396tXW1uLw4cPyx0VFRcjPz0dMTAx69uyJWbNm4cUXX0S/fv2QmpqKv/71r0hMTMTUqVOVu+lfsaysLCxatAjLly9HZGSkPM+t1+sRFhYGvV6Pu+++G7Nnz0ZMTAyioqLw0EMPITMzE5dffrnCd//rM2fOHEyaNAk9e/ZETU0NFi1ahNzcXHz//fd8LRQQGRkp109JwsPD0a1bN/l5viZ+oPRyHiX9+9//Fnv27ClqtVpx5MiR4pYtW5S+pU7hp59+EgGc87j99ttFUbQv7/3rX/8qxsXFiTqdThw/frxYWFio7E3/irX1WgAQFyxYIB/T0NAgPvjgg2LXrl3FLl26iDfccINYXl6u3E3/it11111ir169RK1WK/bo0UMcP368+MMPP8if52uhPOelvaLI18QfBFEURYVyEBEREVHnrBkhIiKi8wfDCBERESmKYYSIiIgUxTBCREREimIYISIiIkUxjBAREZGiGEaIiIhIUQwjREREpCiGESIiIlIUwwgREREpimGEiIiIFMUwQkRERIr6f24UIaTjhJsTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_positive_tanH(nn.Module):\n",
    "    \"\"\"\n",
    "    from positive to all and Hard tanh\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        b2 = torch.concatenate((biases, -biases)) - 1\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.second = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((input_units,), W, b1)\n",
    "        self.second.build((input_units,), W, b2)\n",
    "        self.sub_layer = SubSNNLayer()\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=t_min+1)\n",
    "        tmin2, tmax2, second_val = self.second.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax1)\n",
    "\n",
    "        tmin1, tmax1, first_val = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=tmax2)\n",
    "\n",
    "        tmins, tmaxs, sub_val = self.sub_layer.set_params(t_min, tmax1, first_val,second_val) ## t_min as angument do nothing\n",
    "        self.sub_layer.t_max = tmins+1\n",
    "        return tmins, tmins+1, sub_val\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        out2 = self.second(tj)\n",
    "        sub_ = self.sub_layer(out1,out2)\n",
    "        return sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "input_ttfs = out7.view(out7.size(0), -1)\n",
    "input_x = tmax - input_ttfs\n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "max_vect__ = max_vect\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = SpikingDense_positive_tanH(10,512, '',model2.fc.weight, model2.fc.bias,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\3734511188.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False) +10\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp = layer.set_params(t_min__, t_max__, max_vect__[:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1567], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out_tanh \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ttfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m out_x \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mforward(input_x)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(((t_max \u001b[38;5;241m-\u001b[39m out_tanh)[\u001b[38;5;241m0\u001b[39m,:\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m-\u001b[39m (t_max \u001b[38;5;241m-\u001b[39m out_tanh)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m:] \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mhardtanh(out_x))\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax())\n",
      "Cell \u001b[1;32mIn[1563], line 39\u001b[0m, in \u001b[0;36mSpikingDense_positive_tanH.forward\u001b[1;34m(self, tj)\u001b[0m\n\u001b[0;32m     37\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst(tj)\n\u001b[0;32m     38\u001b[0m out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond(tj)\n\u001b[1;32m---> 39\u001b[0m sub_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sub_\n",
      "File \u001b[1;32mc:\\Users\\nikos\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[1505], line 28\u001b[0m, in \u001b[0;36mSubSNNLayer.forward\u001b[1;34m(self, tj1, tj2)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDDD2 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mamax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_min\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtj1,\u001b[38;5;250m \u001b[39mdim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput1_val)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_min\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtj1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput1_val)\u001b[38;5;241m.\u001b[39many()):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDDD2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDDD2 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mamax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_min\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtj1,\u001b[38;5;250m \u001b[39mdim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput1_val)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "out_tanh = layer.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print(((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:] - F.hardtanh(out_x)).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense_all_all(nn.Module):\n",
    "    \"\"\"\n",
    "    from all to all (pure linear layer)\n",
    "    \"\"\"\n",
    "    def __init__(self, units, input_units, name, weights, biases, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        W1 = torch.concatenate((weights.T, -weights.T),dim=1)\n",
    "        W2 = torch.concatenate((-weights.T, weights.T),dim=1)\n",
    "        W = torch.concatenate((W1,W2),dim=0)\n",
    "        b1 = torch.concatenate((biases, -biases))\n",
    "        self.first = SpikingDense(2*units,\"test\",robustness_params=robustness_params)\n",
    "        self.first.build((2*input_units,), W, b1)\n",
    "\n",
    "\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        tmin1, tmax1, first_val = self.first.set_params(t_min_prev, t_min,in_ranges_max, minimal_t_max=t_min+1)\n",
    "        return tmin1, tmax1, first_val\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        out1 = self.first(tj)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sh = list(input_ttfs.shape)\n",
    "sh[1] = sh[1]\n",
    "binary_mask = torch.randint(0,2,sh)\n",
    "binary_mask = torch.concat((binary_mask, 1-binary_mask),dim=1)\n",
    "sh[1] = sh[1]*2\n",
    "\n",
    "input_ttfs = (torch.rand(sh)*(tmax - tmin) + tmin) * binary_mask\n",
    "input_x = (tmax - input_ttfs[0,:512]) - (tmax - input_ttfs[0,512:]) ### tu bÅ‚Ä…d masz poprawiÄ‡ Å¼e 0 m \n",
    "t_min__ = tmin\n",
    "t_max__ = tmax\n",
    "max_vect__ = torch.rand(1024)\n",
    "print(input_ttfs.shape)\n",
    "print(max_vect__.shape)\n",
    "print(input_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = SpikingDense_all_all(10,512, '',model2.fc.weight, model2.fc.bias,robustness_params=robustness_params)\n",
    "layer_fc = model2.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_19688\\2724487484.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "t_min, t_max, max_vect_temp = layer2.set_params(t_min__, t_max__, max_vect__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor(0.0005, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_tanh = layer2.forward(input_ttfs)\n",
    "out_x = model2.fc.forward(input_x)\n",
    "\n",
    "print(((t_max - out_tanh)[0,:10] - (t_max - out_tanh)[0,10:] - out_x).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(202.3600, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
