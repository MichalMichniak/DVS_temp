{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU(inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        out = F.relu(out, inplace=False)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet3(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet3, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikos\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet3(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet3(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_with_maxpool_same.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na ISNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1],torch.zeros(self.kernel[:-1].shape)), self.kernel[-1].unsqueeze(0)))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        output_val = F.relu(torch.matmul(max_input,max_W))\n",
    "\n",
    "        if self.bias:\n",
    "            max_W = torch.concat((torch.maximum(self.kernel[:-1],torch.zeros(self.kernel[:-1].shape)), torch.maximum(self.kernel[-1].unsqueeze(0),torch.zeros(self.kernel[-1].unsqueeze(0).shape))))\n",
    "            max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = torch.tensor(in_ranges_max)\n",
    "            max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        max_V = F.relu(torch.max(torch.matmul(max_input,max_W)))\n",
    "        \n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, t_min + self.B_n*max_V, output_val\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        print(max_W.shape)\n",
    "        \n",
    "        max_input = (in_ranges_max.unsqueeze(-1).unsqueeze(-1)).to(self.device) * torch.ones(self.kernel.shape[1:]).to(self.device)\n",
    "\n",
    "        print(max_input.shape)\n",
    "        if self.B is not None:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1)))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3))+self.B.squeeze(1))\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))+torch.maximum(self.B.squeeze(1),torch.zeros(self.B.squeeze(1).shape))))\n",
    "        else:\n",
    "            max_V = F.relu(torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3))))\n",
    "            max_values = F.relu(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), max_values\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # Wyciąganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W,self.B.T),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input1_val, input2_val, minimal_t_max = 0):\n",
    "        output_val = input1_val + input2_val\n",
    "        max_V = max(output_val)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), output_val\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj1 + tj2 - 2*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "\n",
    "        max_input = max(in_ranges_max)\n",
    "        max_V = max_input\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max), in_ranges_max\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj - self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, input_val, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1, conv1_val = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, in_ranges_max=conv1_val)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min, in_ranges_max=input_val)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy, downsample_val = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2, in_ranges_max=input_val)\n",
    "\n",
    "        t_min2, t_max2, conv2_val = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy, in_ranges_max=conv1_val)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max, add_val = self.add_layer.set_params(t_min_add, t_max2, conv2_val, downsample_val)\n",
    "\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max, add_val\n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            robustness_params={\n",
    "                'noise':0.0,\n",
    "                'time_bits':0,\n",
    "                'weight_bits': 0,\n",
    "                'latency_quantiles':0.0\n",
    "            }\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, in_ranges_max, minimal_t_max = 0):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax, in_ranges_max = self.layers[i].set_params(tmin, tmax,in_ranges_max)\n",
    "        return tmin, tmax, in_ranges_max\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 7, 7])\n",
      "torch.Size([5, 7, 7])\n",
      "1 tensor(4.1255, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "max_vect = torch.tensor([1,1,1,1,1])\n",
    "tmin, tmax, max_vect = conv_first.set_params(0,1,max_vect)\n",
    "print(tmin, tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "print(model_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6246e-02, 0.0000e+00, 1.4638e-05, 2.4723e+00, 1.1368e-02, 2.3802e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.0605e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.1276e-01, 5.6592e-06, 5.3766e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        3.6908e-03, 1.2543e-02, 0.0000e+00, 0.0000e+00, 1.1855e-02, 1.2451e-02,\n",
      "        0.0000e+00, 4.6424e-02, 1.3234e-05, 0.0000e+00, 0.0000e+00, 6.0138e-03,\n",
      "        8.2080e-02, 2.4156e+00, 0.0000e+00, 2.4081e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.4718e-01, 1.5143e-01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6739e-01, 0.0000e+00, 8.4220e-03,\n",
      "        9.5504e-03, 2.4821e-02, 0.0000e+00, 0.0000e+00, 1.1658e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1255e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2010e-01],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(max_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tworzenie przykładowego array'a\n",
    "values = max_vect.detach().numpy()\n",
    "labels = [ i for i in range(len(max_vect))]\n",
    "\n",
    "# Tworzenie wykresu słupkowego\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "\n",
    "# Dodanie etykiet\n",
    "plt.ylabel('$x_{max}$')\n",
    "plt.xlabel('Channel number')\n",
    "plt.title('maksymalne wartości każdego kanału')\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "out1_x = model2.conv1(random_input)\n",
    "print(((conv_first.t_max - out1) - out1_x).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "\n",
    "print(((tmax - out2) - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = None\n",
    "\n",
    "# resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy, device='cpu')\n",
    "# tmin, tmax, max_vect = resblockSNN.set_params(0,1, max_vect)\n",
    "# print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "tensor(37.9667, grad_fn=<AddBackward0>) tensor(44.3500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\623020791.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\623020791.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer0SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0177e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(out2)\n",
    "\n",
    "print((tmax - out_3 - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([64, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([64, 1, 1])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([64, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "tensor(108.7806, grad_fn=<AddBackward0>) tensor(117.9561, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\623020791.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer1SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5410e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "\n",
    "print((tmax - out_4 - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([128, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\623020791.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2473.7261, grad_fn=<AddBackward0>) tensor(2721.6611, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer2SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0006, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print((tmax - out_5 - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([256, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([256, 1, 1])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([256, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512, 3, 3])\n",
      "tensor(89231.7266, grad_fn=<AddBackward0>) tensor(122486.8594, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\420536755.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2640231386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\623020791.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN(model2.layer3, 256, 512, 3,device = 'cpu')\n",
    "tmin, tmax, max_vect = layer3SNN.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0172, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print((tmax - out_6 - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0172, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6)\n",
    "\n",
    "print(((tmax - out7) - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(122486.8594, grad_fn=<AddBackward0>) tensor(175560.3750, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2041431043.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2041431043.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_input = torch.concat((torch.tensor(in_ranges_max), torch.tensor([(1)])))\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2041431043.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2041431043.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_25812\\2041431043.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T\n",
    "biases = model2.fc.bias\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin, tmax, max_vect = spiking_dense.set_params(tmin, tmax, max_vect)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor(0.0090, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "\n",
    "print((tmax - out8 - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(4.1255, grad_fn=<AddBackward0>), tensor(6.0704, grad_fn=<AddBackward0>), 'c'), (tensor(6.0704, grad_fn=<AddBackward0>), tensor(12.5547, grad_fn=<AddBackward0>), 'c'), (tensor(12.5547, grad_fn=<AddBackward0>), tensor(18.9077, grad_fn=<AddBackward0>), 'a'), (tensor(18.9077, grad_fn=<AddBackward0>), tensor(19.8904, grad_fn=<AddBackward0>), 'c'), (tensor(19.8904, grad_fn=<AddBackward0>), tensor(25.2607, grad_fn=<AddBackward0>), 'c'), (tensor(25.2607, grad_fn=<AddBackward0>), tensor(31.6137, grad_fn=<AddBackward0>), 'a'), (tensor(31.6137, grad_fn=<AddBackward0>), tensor(32.0402, grad_fn=<AddBackward0>), 'c'), (tensor(32.0402, grad_fn=<AddBackward0>), tensor(37.9667, grad_fn=<AddBackward0>), 'c'), (tensor(37.9667, grad_fn=<AddBackward0>), tensor(44.3500, grad_fn=<AddBackward0>), 'a'), (tensor(44.3500, grad_fn=<AddBackward0>), tensor(46.2573, grad_fn=<AddBackward0>), 'c'), (tensor(46.2573, grad_fn=<AddBackward0>), tensor(54.3759, grad_fn=<AddBackward0>), 'c'), (tensor(54.3759, grad_fn=<AddBackward0>), tensor(63.3910, grad_fn=<AddBackward0>), 'a'), (tensor(63.3910, grad_fn=<AddBackward0>), tensor(63.3911, grad_fn=<AddBackward0>), 'c'), (tensor(63.3911, grad_fn=<AddBackward0>), tensor(72.4062, grad_fn=<AddBackward0>), 'c'), (tensor(72.4062, grad_fn=<AddBackward0>), tensor(81.4214, grad_fn=<AddBackward0>), 'a'), (tensor(81.4214, grad_fn=<AddBackward0>), tensor(83.4420, grad_fn=<AddBackward0>), 'c'), (tensor(83.4420, grad_fn=<AddBackward0>), tensor(90.4366, grad_fn=<AddBackward0>), 'c'), (tensor(90.4366, grad_fn=<AddBackward0>), tensor(99.6086, grad_fn=<AddBackward0>), 'a'), (tensor(99.6086, grad_fn=<AddBackward0>), tensor(99.6087, grad_fn=<AddBackward0>), 'c'), (tensor(99.6087, grad_fn=<AddBackward0>), tensor(108.7806, grad_fn=<AddBackward0>), 'c'), (tensor(108.7806, grad_fn=<AddBackward0>), tensor(117.9561, grad_fn=<AddBackward0>), 'a'), (tensor(117.9561, grad_fn=<AddBackward0>), tensor(133.2086, grad_fn=<AddBackward0>), 'c'), (tensor(133.2086, grad_fn=<AddBackward0>), tensor(159.3715, grad_fn=<AddBackward0>), 'c'), (tensor(159.3715, grad_fn=<AddBackward0>), tensor(187.2562, grad_fn=<AddBackward0>), 'a'), (tensor(187.2562, grad_fn=<AddBackward0>), tensor(242.6957, grad_fn=<AddBackward0>), 'c'), (tensor(242.6957, grad_fn=<AddBackward0>), tensor(490.2449, grad_fn=<AddBackward0>), 'c'), (tensor(490.2449, grad_fn=<AddBackward0>), tensor(738.1801, grad_fn=<AddBackward0>), 'a'), (tensor(738.1801, grad_fn=<AddBackward0>), tensor(738.3481, grad_fn=<AddBackward0>), 'c'), (tensor(738.3481, grad_fn=<AddBackward0>), tensor(986.1152, grad_fn=<AddBackward0>), 'c'), (tensor(986.1152, grad_fn=<AddBackward0>), tensor(1234.0504, grad_fn=<AddBackward0>), 'a'), (tensor(1234.0504, grad_fn=<AddBackward0>), tensor(1271.8289, grad_fn=<AddBackward0>), 'c'), (tensor(1271.8289, grad_fn=<AddBackward0>), tensor(1481.9856, grad_fn=<AddBackward0>), 'c'), (tensor(1481.9856, grad_fn=<AddBackward0>), tensor(1729.9208, grad_fn=<AddBackward0>), 'a'), (tensor(1729.9208, grad_fn=<AddBackward0>), tensor(1729.9276, grad_fn=<AddBackward0>), 'c'), (tensor(1729.9276, grad_fn=<AddBackward0>), tensor(1977.8560, grad_fn=<AddBackward0>), 'c'), (tensor(1977.8560, grad_fn=<AddBackward0>), tensor(2225.7910, grad_fn=<AddBackward0>), 'a'), (tensor(2225.7910, grad_fn=<AddBackward0>), tensor(2225.7915, grad_fn=<AddBackward0>), 'c'), (tensor(2225.7915, grad_fn=<AddBackward0>), tensor(2473.7261, grad_fn=<AddBackward0>), 'c'), (tensor(2473.7261, grad_fn=<AddBackward0>), tensor(2721.6611, grad_fn=<AddBackward0>), 'a'), (tensor(2721.6611, grad_fn=<AddBackward0>), tensor(3043.3770, grad_fn=<AddBackward0>), 'c'), (tensor(3043.3770, grad_fn=<AddBackward0>), tensor(5258.3521, grad_fn=<AddBackward0>), 'c'), (tensor(5258.3521, grad_fn=<AddBackward0>), tensor(7496.3623, grad_fn=<AddBackward0>), 'a'), (tensor(7496.3623, grad_fn=<AddBackward0>), tensor(9660.8828, grad_fn=<AddBackward0>), 'c'), (tensor(9660.8828, grad_fn=<AddBackward0>), tensor(35876.1172, grad_fn=<AddBackward0>), 'c'), (tensor(35876.1172, grad_fn=<AddBackward0>), tensor(62553.9219, grad_fn=<AddBackward0>), 'a'), (tensor(62553.9219, grad_fn=<AddBackward0>), tensor(64883.4102, grad_fn=<AddBackward0>), 'c'), (tensor(64883.4102, grad_fn=<AddBackward0>), tensor(89231.7266, grad_fn=<AddBackward0>), 'c'), (tensor(89231.7266, grad_fn=<AddBackward0>), tensor(122486.8594, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'czas')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(tt)\n",
    "plt.xlabel(\"Nr. warstwy\")\n",
    "plt.ylabel(\"czas\")\n",
    "# plt.ylim([0,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [(tt[i])/(tt[i-1]) for i in range(2,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x192eefd32b0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
